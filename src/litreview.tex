\chapter{Literature review\label{cha:litreivew}}

\section{Foundations: Biomedical Imaging \& Segmentation Basics}

\subsection{Imaging across scales: EM, optical LM, and MRI--PET}
\label{sec:foundations-imaging-scales}

Biomedical imaging for human brain segmentation spans more than six orders of magnitude in spatial scale, with each modality coupling characteristic signal physics to distinct constraints on field of view, contrast, artefacts, and annotatability. Here we synthesise the essentials of electron microscopy (EM), optical light microscopy (LM), and magnetic resonance imaging--positron emission tomography (MRI--PET), emphasising how scale and signal properties shape feasible segmentation formulations and evaluation. Throughout this review we adopt Australian and British spelling conventions (e.g., stabilise, generalisation) to align with institutional guidance.

\noindent\textbf{Electron microscopy (EM).}
EM delivers nanometre-scale resolution sufficient to resolve ultrastructures such as synaptic clefts, vesicles, and membranes, at the cost of extreme data volumes and acquisition idiosyncrasies. Serial-section transmission electron microscopy (ssTEM), block-face scanning electron microscopy (SEM; notably serial block-face electron microscopy, SBEM), and focused ion beam scanning electron microscopy (FIB-SEM) produce teravoxel-to-petavoxel three-dimensional volumes; exhaustive manual annotation is infeasible, and high-quality labels typically cover only small subvolumes \parencite{Alzubaidi2025,Buhmann2021}. Practical obstacles include through-plane anisotropy (notably in serial stacks), section misalignments or dropouts, staining and contrast variability across labs and protocols, and pronounced domain shifts between species and tissue regions that degrade cross-dataset generalisation \parencite{Li2024WASPSYN,Alzubaidi2025}. For segmentation, these constraints favour three-dimensional context (to disambiguate slice-ambiguous appearances) and instance-level formulations (to separate adjacent synaptic elements and avoid merge or split errors), frequently augmented with structural priors from neuron-contact graphs to enforce biologically plausible partner assignments \parencite{Buhmann2021}.

\noindent\textbf{Optical light microscopy (LM).} 
Confocal, two-photon, light-sheet, and super-resolution LM extend coverage to larger tissue volumes with sub-micron voxels and multiplexed molecular contrast, but cannot generally delineate all ultrastructural boundaries. In immunofluorescence, synapses often appear as puncta or co-localised channels for pre- and postsynaptic markers, steering methods toward small-object instance detection with careful intensity normalisation, deconvolution, and stain harmonisation \parencite{Nazac2025}. At mesoscopic scales (e.g., cleared-brain light-sheet imaging), whole-brain volumes reach teravoxels; robust cell and nuclei segmentation relies on three-dimensional architectures and data-efficient learning (self-supervised and weakly supervised regimes) to counter protocol variability and sparse annotations \parencite{Achard2025CellSeg3D,Attarpour2025}. Inter-laboratory differences in optics, labelling chemistry, and tissue clearing introduce substantial domain shifts; pipelines therefore emphasise cross-site normalisation, augmentations that mimic optical artefacts, and test-time adaptation to stabilise predictions across microscopes and preparations \parencite{Achard2025CellSeg3D}.

\noindent\textbf{MRI--PET (macro-scale anatomical and molecular imaging).} 
Structural MRI (e.g., T1-, T2-weighted, FLAIR) provides millimetre-scale whole-brain anatomy suited to tissue and region segmentation, often via three-dimensional voxelwise models or surface-aware pipelines. Confounds include bias-field inhomogeneity, partial-volume effects, motion, and heterogeneous acquisition protocols that challenge cross-site generalisation \parencite{Nishimaki2024OpenMAPT1,Ren2025DeepPrep}. Positron emission tomography (PET) cannot resolve single synapses; radioligands such as SV2A yield \emph{in vivo} maps of regional synaptic density that are analysed at the parcel or region-of-interest (ROI) level and co-registered to MRI for anatomical localisation \parencite{Johansen2024}. Recent probabilistic histological atlases inject spatial priors for small subcortical nuclei and cortical fields into MRI parcellation, improving consistency of region boundaries where image contrast is weak \parencite{Casamitjana2025}. In multimodal settings (e.g., hybrid PET--MR systems), segmentation couples modality fusion with mechanisms for missing sequences and scanner variability, prioritising reproducibility and calibration across sites \parencite{Ren2025DeepPrep}.

\noindent\textbf{Implications across scales.} 
Scale dictates both what is segmentable and how success should be measured. EM invites instance-level, topology-aware segmentation where voxel-level mistakes can alter connectivity; LM emphasises small-object detection under optical variability; MRI--PET targets macro-anatomical parcels and regional quantification under cross-scanner shifts. These differences motivate modality-specific architectures (two-dimensional vs.\ three-dimensional; voxel- vs.\ surface-based), training regimes (self- and semi-supervision to offset scarce labels), and evaluation (from Dice and IoU with boundary distances to instance-level average precision and synaptic partnership accuracy), while underscoring a unifying need for domain-robust representations and biologically and plausibly constrained outputs across the imaging spectrum.

\subsection{Segmentation formulations}
\label{sec:foundations-seg-formulations}

Segmentation in neuroimaging spans multiple output formulations whose suitability depends on imaging scale, annotation availability, and downstream analysis. We distinguish \emph{semantic}, \emph{instance}, and \emph{panoptic} segmentation, and further contrast point or partner detection with mask-based predictions, before outlining a graph-theoretic perspective that is particularly relevant for synapses and cellular structures.

\noindent\textbf{Semantic, instance, and panoptic outputs.}
\emph{Semantic segmentation} assigns each voxel and pixel to a class label without distinguishing individual objects. It underlies many region-level MRI parcellations (e.g., cortex vs.\ subcortical nuclei) where object identity is not required. By contrast, \emph{instance segmentation} differentiates distinct objects within the same class (e.g., individual synapses or cells), enabling counts, size distributions, and partner-specific analyses. In biomedical practice, instance segmentation is achieved either by detection\,$\to$\,masking pipelines (e.g., region proposal and refinement as in \parencite{He2017MaskRCNN}) or proposal-free decoders that condition on per-location embeddings and parameters (\parencite{Tian2020CondInst}). \emph{Panoptic segmentation} unifies the two by jointly predicting instance masks for \emph{things} and semantic labels for \emph{stuff}, with quality assessed by Panoptic Quality (PQ), a combined detection-and-overlap measure \parencite{Kirillov2019Panoptic}. Recent universal decoders (e.g., Mask2Former) further standardise mask prediction across tasks by learning mask embeddings and attention-based decoders \parencite{Cheng2022Mask2Former}. At synapse or cell scales, instance or panoptic formulations are preferable to prevent merges of adjacent objects and to enable biologically meaningful counting; at region scale, semantic outputs (possibly augmented with shape and atlas priors) dominate.

\noindent\textbf{Point and partner detection vs.\ mask segmentation.}
For structures that are small, sparsely labelled, or ambiguous at the voxel level (e.g., synaptic puncta in LM, synaptic clefts in anisotropic EM), \emph{point detection} offers a pragmatic alternative to dense masks. Models predict heatmaps or coordinates for object centroids and, in synaptic applications, may additionally output \emph{paired} locations or identities of pre- and post-synaptic partners; evaluation then relies on distance-tolerant matching and partner-assignment accuracy (cf.\ \parencite{Buhmann2021}). Mask-based formulations remain essential when morphology matters (e.g., cell bodies, neurites, macro-anatomical parcels), with losses combining region overlap (Dice and IoU) and boundary distances (HD95 and ASSD). Instance-level metrics such as Average Precision (AP), Aggregated Jaccard Index (AJI), and PQ capture detection–segmentation trade-offs and are preferable to pixel-only scores in crowded scenes \parencite{Kirillov2019Panoptic,Kumar2017AJI}.

\noindent\textbf{A graph-theoretic view of segmentation.}
Many neurobiological targets are naturally relational. In EM connectomics, neurons form a contact graph whose edges correspond to synapses; in cortical parcellation, surface meshes or tractography graphs encode anatomical adjacency. Casting segmentation as \emph{graph construction and labelling} enables the injection of structural priors (e.g., synapses must connect two distinct neurites) and yields task-aligned objectives (e.g., maximising correct edges rather than voxel overlap). Practically, pipelines either (i) segment candidate structures and then infer connectivity on graphs (e.g., classify axon–dendrite contacts as synaptic vs.\ non-synaptic; \parencite{Buhmann2021}), or (ii) predict graph elements directly and render masks secondarily. Topology-preserving objectives (e.g., cliques and centerlines, homology-inspired or projection-based constraints) further reduce biologically implausible splits and merges by penalising errors that alter connectivity \parencite{Fu2024ProjectedPooling,Clough2020TopoLoss}. This perspective is especially valuable when voxel-level inaccuracies have outsized impact on downstream connectome correctness, or when outputs must respect atlas-informed adjacency on cortical surfaces.

\noindent\textbf{Design implications.}
Choice of formulation dictates architecture and evaluation. At synapse or cell scales, instance or panoptic decoders (proposal-based or proposal-free) with 3D context and topology-aware losses curb merge or split errors; point or partner detectors are preferred when labels are sparse or morphology is unresolved. At region scale, semantic decoders augmented with atlas and shape priors and surface or graph representations better capture thin cortical sheets and small nuclei. In all cases, instance-aware metrics (AP, AJI, PQ) should complement voxel overlap and boundary distances to reflect the intended biological utility of the segmentation.

\subsection{2D, 2.5D, and 3D trade-offs}
\label{sec:foundations-2d25d3d}

Choosing between 2D, 2.5D, and 3D formulations hinges on volumetric anisotropy, annotation regime, computational budget, and the geometric fidelity required by downstream analyses. Here we contrast the representational capacity and practical constraints of each option and relate them to voxel- and surface-based processing pipelines.

\noindent\textbf{2D slice-wise models.}
Purely 2D networks process images one slice at a time and have favourable memory and computation footprints, enabling large effective batch sizes, heavy augmentations, and rapid experimentation. Historically, strong 2D baselines—often with multi-view ensembling—achieved competitive results on MRI lesions and microscopy nuclei where through-plane context is limited or severely anisotropic \parencite{Havaei2017BrainTumor}. However, ignoring the axial dimension sacrifices 3D continuity: boundaries may oscillate across slices, small targets disappear, and instance identities drift in crowded scenes. Such slice inconsistency is particularly harmful for ultrastructure (e.g., synapses, thin neurites) and for volumetric metrics sensitive to topology.

\noindent\textbf{2.5D context.}
2.5D designs inject limited through-plane context while retaining 2D convolutions. Common strategies include (i) stacking $k$ neighbouring slices as channels, (ii) tri-planar networks that fuse orthogonal views, and (iii) anisotropic operations (e.g., $3{\times}3{\times}1$ kernels in early layers) to respect coarse through-plane resolution \parencite{Havaei2017BrainTumor,Isensee2021nnUNet}. These variants recover local 3D cues at modest cost and reduce slice-to-slice flicker. Their limitations are systematic: receptive fields remain short along $z$, long-range 3D dependencies are under-modelled, and view fusion can introduce inconsistencies if planes disagree. Consequently, 2.5D is well-suited to anisotropic EM stacks and clinical MRI with thick slices, but underperforms true 3D on tasks requiring coherent volumetric geometry.

\noindent\textbf{3D volumetric models.}
3D CNNs (e.g., 3D U-Net and V-Net) natively capture spatial continuity and shape, yielding superior topology and small-structure sensitivity across modalities when memory permits \parencite{Cicek2016UNet3D,Milletari2016VNet}. In practice, memory scales with patch size and feature width; training and inference therefore rely on (overlap-)tiling and patch-wise sliding windows, sometimes in cascades (coarse low-resolution stage $\rightarrow$ full-resolution refinement) and with halo margins to suppress edge artefacts \parencite{Ronneberger2015UNet,Isensee2021nnUNet}. For anisotropic data, resampling to quasi-isotropy or using anisotropic kernels and strides in early stages preserves fidelity while controlling cost; large-context 3D backbones (multi-scale encoders, dilated and strided blocks) further extend effective receptive fields without prohibitive memory. Sparse and submanifold convolutions can accelerate 3D inference for filamentary targets (e.g., vessels and neurites) by avoiding dense computation on empty space \parencite{Graham2018Submanifold}.

\noindent\textbf{Voxel vs.\ surface pipelines.}
Voxel-based pipelines (2D, 2.5D, and 3D) directly predict labels in the volume and are natural for subcortical nuclei, lesions, cells, and synapses. Cortical analysis, by contrast, often benefits from surface-based processing: images are projected to white and pial meshes or spheres, and segmentation and parcellation proceeds on surfaces that preserve cortical topology and thickness while mitigating partial-volume effects \parencite{Dale1999,Fischl2012}. Surface pipelines enable anatomically meaningful constraints (sulcal–gyral alignment, left–right symmetry) and facilitate multi-modal fusion on a common surface coordinate system (e.g., HCP’s multi-modal parcellation) \parencite{Glasser2016}. Recent work combines voxelwise deep models with surface reconstruction or employs mesh and spherical CNNs and fast learning-based surface reconstructions to scale clinical workflows \parencite{Henschel2020FastSurfer,Isensee2021nnUNet}.

\noindent\textbf{Design guidance.}
For anisotropic EM or thick-slice MRI, 2.5D with anisotropic operations can stabilise predictions at low cost; when geometry and topology matter (synapses, neurites, small nuclei), 3D models with tiling and cascades are preferable. Voxel pipelines suit volumetric targets and multimodal fusion, whereas surface pipelines are advantageous for cortex-specific tasks and cross-subject alignment. Across regimes, robust deployment hinges on careful handling of patching (overlap and halo), calibration of receptive fields to structure size, and, where feasible, incorporation of topology-aware objectives to preserve connectivity.

\subsection{Evaluation and fair comparison}
\label{sec:foundations-eval-fair}

Robust assessment of segmentation requires a \emph{family} of complementary metrics that jointly probe region overlap, boundary accuracy, instance correctness, and (where applicable) graph or partnership validity. Relying on a single score obscures important failure modes; consequently, it is advisable to report overlap, distance, and instance- or graph-aware measures alongside clear experimental hygiene for fair comparison.

\noindent\textbf{Region-overlap metrics (Dice and IoU).}
Let $X$ and $Y$ denote predicted and reference masks. The Dice similarity coefficient (DSC) and the Jaccard index (IoU) are defined as
\begin{equation}
\label{eq:dice-iou-def}
\mathrm{DSC} = \frac{2\,|X \cap Y|}{|X| + |Y|},
\qquad
\mathrm{IoU} = \frac{|X \cap Y|}{|X \cup Y|}.
\end{equation}
Their monotonic relationship,
\begin{equation}
\label{eq:dice-iou-relationship}
\mathrm{DSC} = \frac{2\,\mathrm{IoU}}{1+\mathrm{IoU}},
\end{equation}
is frequently exploited when comparing studies that report only one of the two scores. Dice and IoU are scale-agnostic region overlaps and remain the most widely reported summary scores in biomedical segmentation, including brain MR parcellation and microscopy \parencite{Isensee2021nnUNet,Menze2015BRATS}. However, they can mask thin-boundary errors (high DSC with boundary offsets) and are biased toward large structures; stratifying by object size and complementing with boundary metrics is therefore essential \parencite{Taha2015Metrics}.

\noindent\textbf{Boundary-distance metrics (HD95 and ASSD).}
Distance-based metrics quantify contour fidelity. The (symmetric) Hausdorff distance (HD) captures the maximum surface discrepancy but is sensitive to outliers; the $95^{\mathrm{th}}$ percentile HD (HD95) mitigates this by discarding the worst $5\%$ of surface distances. The average symmetric surface distance (ASSD) averages bidirectional surface distances, reflecting typical boundary error \parencite{Taha2015Metrics,Menze2015BRATS}. In neuroimaging, HD95 is often preferred to HD for robustness, while ASSD complements DSC by revealing systematic boundary shifts. A profile of \{DSC, HD95, ASSD\} thus separates \enquote{good overlap, poor boundary} from \enquote{moderate overlap, tight boundary} regimes.

\noindent\textbf{Instance-aware metrics (AJI, PQ, and AP).}
Crowded scenes (cells, synapses) require metrics that account for object identity. The Aggregated Jaccard Index (AJI) extends IoU to a one-to-one matching between predicted and reference instances, penalising both over- and under-segmentation \parencite{Kumar2017AJI}. Panoptic Quality (PQ) jointly measures detection and segmentation quality by combining segmentation quality (SQ) and recognition quality (RQ) over matched instances \parencite{Kirillov2019Panoptic}. Average Precision (AP), popularised by COCO, evaluates detection or instance segmentation across IoU thresholds (typically $0.50\text{--}0.95$ in steps of $0.05$), reflecting the precision–recall trade-off under varying overlap criteria \parencite{Lin2014COCO}. Reporting AJI, PQ, and AP alongside Dice and IoU provides a more faithful picture in multi-instance, touching-object scenarios.

\noindent\textbf{Graph- and partnership-aware metrics (connectomics).}
When predictions imply relationships—e.g., synapses as edges between neurites—the objective shifts from voxel accuracy to \emph{graph correctness}. Synaptic \emph{partnership accuracy} measures whether each detected synapse links the correct pre- and postsynaptic partners; edge-wise precision and recall or F1 on the predicted connectivity graph are natural summaries \parencite{Buhmann2021}. These measures detect biologically critical errors (partner misassignment) that region-only metrics cannot capture and should accompany overlap scores whenever downstream analyses consume connectomes.

\noindent\textbf{Multi-metric interpretation.}
Joint reporting enables diagnostic reading: (i) high DSC with large HD95 suggests adequate overlap but boundary \emph{fly-outs} (e.g., spurious protrusions); (ii) high precision but low recall in AP and PQ indicates conservative detection (missed small targets), whereas the converse indicates over-segmentation; (iii) improved AJI with stagnant DSC typically reflects better instance disentanglement at constant pixel overlap; (iv) good DSC and HD95 but poor partnership accuracy flags topologically implausible assignments despite visually plausible masks. It is helpful to summarise metrics by structure size (small, medium, and large), report confidence intervals via bootstrapping, and fix post-processing and matching protocols (e.g., IoU thresholds, distance tolerances) to avoid cherry-picking \parencite{Taha2015Metrics}. For cross-site studies, stratify results by scanner and protocol and include strong self-configuring baselines (e.g., nnU-Net) to contextualise claimed gains \parencite{Isensee2021nnUNet}.

\noindent\textbf{Fair-comparison hygiene.}
To ensure comparability: (a) use \emph{identical} data splits or cross-validation folds and prevent test leakage; (b) perform model selection on validation sets only; (c) fix pre- and post-processing (resampling, normalisation, connected-component rules); (d) report hyperparameters, training budgets, and multiple seeds; (e) disclose ensembling and test-time augmentation; (f) release code and evaluation scripts. Challenges such as BraTS illustrate the value of hidden test sets and standardised metric scripts to stabilise rankings across years \parencite{Menze2015BRATS}. Absent such infrastructure, transparent protocols and multi-metric reporting remain the most effective defence against irreproducible or inflated claims.

\subsection{Reproducibility and comparison hygiene}
\label{sec:foundations-reproducibility}

Fair comparison in neuroimaging segmentation hinges on rigorous experimental hygiene: preventing data leakage, enforcing split consistency, demonstrating cross-dataset generalisation, and adopting transparent reporting practices. Absent these safeguards, apparent gains can reflect protocol artefacts rather than genuine algorithmic improvements.

\noindent\textbf{Leakage risks and prevention.}
Data leakage occurs when information from the evaluation set influences model fitting, hyperparameter selection, or pre- and post-processing \parencite{Kaufman2012Leakage}. In volumetric settings, typical pitfalls include: (i) \emph{subject-level leakage}—patch- or slice-level splits that place volumes from the same subject (or neighbouring slices from the same stack) into both train and test; (ii) \emph{preprocessing leakage}—normalisation, bias-field correction, or stain harmonisation parameters estimated across the full dataset rather than per-training fold; (iii) \emph{registration and atlas leakage}—learning registration or atlas-adaptation parameters using test images; (iv) \emph{test-aware model selection}—tuning thresholds, ensembling weights, or post-processing on the test set. Mitigations are straightforward but non-negotiable: split at the \emph{subject} (and, where applicable, \emph{site}) level; fit all preprocessing exclusively on training data within each fold; isolate validation from test for hyperparameter selection; and lock post-processing prior to test submission.

\noindent\textbf{Split design and consistency.}
To ensure comparability across studies, use identical data splits (or stratified $k$-folds) when benchmarking, publish hashable split manifests, and control random seeds. Nested cross-validation prevents optimistic bias when selecting hyperparameters. For multi-centre cohorts, stratify splits by scanner and protocol and pathology distribution to avoid accidental covariate imbalance. When reusing public challenges (e.g., BraTS), adhere to their prescribed training and validation protocols and rely on hidden test sets for final ranking \parencite{Menze2015BRATS}. Strong, self-configuring baselines such as nnU-Net provide an anchor for effect sizes under the same splits and preprocessing \parencite{Isensee2021nnUNet}.

\noindent\textbf{External validation and domain shift.}
In medical imaging, distribution shift across hospitals, devices, and acquisition protocols can dwarf in-domain improvements. Consequently, beyond internal cross-validation, report external validation on \emph{unseen} sites or datasets whenever available. Cross-hospital studies in radiography show that models with excellent internal metrics may suffer large performance drops when deployed elsewhere \parencite{Zech2018Generalization}. For segmentation, we recommend reporting per-site performance, subgroup stratifications (e.g., scanner vendor, field strength, age), and calibration curves to quantify uncertainty and overconfidence \parencite{Guo2017Calibration}. When external data are inaccessible, at minimum simulate shift via leave-one-site-out validation and ablations on resolution and contrast perturbations.

\noindent\textbf{Transparent reporting and statistical evidence.}
Adopt established reporting checklists to standardise disclosures (dataset composition, inclusion and exclusion, ground-truth protocols, preprocessing, model configuration, training budgets, and evaluation scripts) \parencite{Mongan2020CLAIM}. Release code, exact splits, and containerised environments to maximise computational reproducibility. Provide \emph{multi-metric} results (DSC and IoU, HD95 and ASSD, AJI, PQ, and AP, partnership accuracy where relevant) with uncertainty intervals: nonparametric bootstrap confidence intervals over cases are simple and robust \parencite{Taha2015Metrics,Efron1994Bootstrap}. Report multiple random seeds and ablate key design choices (2D vs.\ 3D; voxel vs.\ surface; with and without domain adaptation). Finally, accompany results with concise model and dataset documentation (``model cards''/``data sheets'') to clarify intended use, limitations, and shift sensitivities \parencite{Mitchell2019ModelCards}.

\noindent\textbf{Putting it together.}
A credible evaluation protocol thus comprises: (i) leakage-safe, subject- and site-level splits with public manifests; (ii) a strong self-configuring baseline (e.g., nnU-Net) under the same pipeline; (iii) internal \emph{and} external validation with per-site stratification and calibration; (iv) multi-metric reporting with uncertainty; and (v) full transparency of code, parameters, and evaluation scripts. These practices convert raw scores into reliable scientific evidence and enable the community to separate genuine algorithmic advances from procedural variance.

\section{Synapse-level Segmentation}

\subsection{Problem characteristics}
\label{sec:synapse-problem-characteristics}

Synapse-level segmentation operates at the intersection of extreme spatial density, minute object scale, severe class imbalance, scarce annotations, and pronounced domain shift. These factors jointly shape what is learnable, which formulations are viable, and how models must be evaluated.

\noindent\textbf{Ultra-dense packing and minute scale.}
Chemical synapses occupy only a handful of voxels at nanometre resolutions, yet occur at extremely high densities in neuropil. In EM, a single voxel-level misclassification can fuse neighbouring neurites (\emph{merge}) or fracture a synaptic cleft (\emph{split}), altering downstream connectivity. Anisotropic acquisitions (e.g., serial sections) exacerbate through-plane ambiguity, while section misalignments and occasional dropouts break local continuity \parencite{Alzubaidi2025}. Consequently, robust segmentation requires 3D context wherever memory permits and instance-aware decoders that explicitly prevent object mergers in crowded scenes \parencite{Alzubaidi2025,Buhmann2021}.

\noindent\textbf{Severe class imbalance and morphological ambiguity.}
At the voxel level, synaptic structures represent a minute fraction of the volume relative to background membranes, cytoplasm, and organelles. This imbalance propagates to instances: small, low-contrast synapses are easily missed, whereas look-alike ultrastructures (e.g., mitochondria, dense-core vesicles, membrane appositions) trigger false positives, especially in slice-wise models lacking axial context \parencite{Alzubaidi2025}. In LM, synapses often appear as diffraction-limited puncta or co-localised fluorescent spots; morphology is under-resolved and requires intensity normalisation and stain harmonisation to stabilise detection \parencite{Nazac2025}. Effective systems therefore combine cost-sensitive objectives, small-object priors, and component-aware multitask heads (e.g., vesicles and active zones) to disambiguate synaptic patterns \parencite{Alzubaidi2025,Buhmann2021}.

\noindent\textbf{Annotation scarcity and label noise.}
Large-scale human EM with dense synapse labels remains rare due to ethical, technical, and labour constraints; annotation typically covers only small subvolumes, and inter-rater variability introduces boundary uncertainty \parencite{Alzubaidi2025}. Weak labels are common in LM (points and centres rather than masks), pushing methods toward point or partner detection with distance-tolerant matching. These realities privilege data-efficient learning (self-supervision and semi-supervision, active learning) and rigorous uncertainty reporting to prioritise human review where models are least certain \parencite{Alzubaidi2025}.

\noindent\textbf{Domain shift across species, tissue, and modality.}
Preparation protocols (fixatives, stains), imaging modality (TEM, SBEM, FIB-SEM), laboratory pipelines, and tissue and species differences induce substantial appearance shifts that degrade cross-dataset performance \parencite{Alzubaidi2025}. Recent community benchmarks emphasise \emph{domain adaptation} for synapse detection, underscoring the gap between in-domain accuracy and out-of-domain generalisation \parencite{Li2024WASPSYN}. At the macroscale, in vivo PET can only infer regional synaptic density (e.g., SV2A binding) rather than resolve individual synapses, reinforcing that cross-scale integration must treat synapses statistically at MRI and PET scales while preserving instance fidelity in EM and LM \parencite{Johansen2024}. In practice, robust pipelines adopt multi-domain training, style and contrast augmentations, adaptive normalisation, and, where feasible, graph constraints tying synapse candidates to neurite contacts to maintain biological plausibility under shift \parencite{Buhmann2021,Li2024WASPSYN}.

\noindent\textbf{Implications.}
The conjunction of ultra-dense targets, minute scale, imbalance, sparse labels, and shift makes synapse segmentation uniquely sensitive to (i) instance-aware formulations with topology-preserving objectives, (ii) 3D context or anisotropy-aware 2.5D designs, (iii) data-efficient training with explicit small-object handling, and (iv) evaluation that goes beyond region overlap to include instance metrics and \emph{synaptic partnership accuracy} to reflect connectome correctness \parencite{Buhmann2021,Alzubaidi2025}.

\subsection{Classical pipelines (pre-DL)}
\label{sec:synapse-classical}

Before deep learning, synapse segmentation relied on hand-crafted image processing and shallow learning, typically arranged in a modular pipeline of preprocessing, candidate generation, decision making, and post hoc correction. While such systems enabled early large-scale analyses, their performance and portability were limited by sensitivity to acquisition idiosyncrasies and labour-intensive proofreading.

\noindent\textbf{Preprocessing and candidate generation.}
Early pipelines enhanced ultrastructural contrast via denoising, bias and illumination correction, and stain normalisation, followed by heuristic detection of \enquote{synaptic-like} patterns. Global or adaptive thresholding \parencite{Otsu1979} and edge and gradient operators (e.g., Canny) \parencite{Canny1986} provided coarse candidates; morphological filtering and watershed transforms segmented electron-dense regions into putative clefts or boutons \parencite{BeucherMeyer1992}. Region adjacency graphs or graph-based over-segmentations (e.g., Felzenszwalb–Huttenlocher) delineated superpixels and supervoxels for subsequent merging \parencite{Felzenszwalb2004}. Active contour models (Chan–Vese) captured smooth boundaries where gradients were weak \parencite{ChanVese2001}, and interactive graph-cut variants (GrabCut; Boykov–Jolly) enabled user-steered refinement on difficult membranes \parencite{BoykovJolly2001,Rother2004GrabCut}.

\noindent\textbf{Hand-crafted features and shallow classifiers.}
A common strategy framed synapse recognition as pixel-/superpixel-wise classification using texture, intensity, and context descriptors (e.g., local statistics, steerable filters, LoG blobs). Random forests or SVMs trained on sparse labels produced synapse likelihood maps, subsequently regularised by Markov and conditional random fields to enforce local consistency and edge alignment \parencite{Felzenszwalb2004,Krahenbuhl2011CRF}. Importantly, annotation was often \emph{interactive}: tools such as \textit{ilastik} allowed experts to brush a handful of positive and negative examples and iteratively update classifiers, yielding practical accuracy with limited labels and providing an efficient proofreading loop \parencite{Sommer2011Ilastik}. These semi-automatic workflows made teravoxel volumes tractable by focusing expert time on systematic errors rather than exhaustive manual tracing.

\noindent\textbf{Graphical and morphological regularisation.}
Beyond local classification, pipelines incorporated structural priors via graph formulations. Watershed regions or supervoxels formed nodes in a region adjacency graph; graph-cut and merging schemes optimised an energy that balanced data fidelity with boundary penalties, while CRFs aligned labels to membrane edges \parencite{BeucherMeyer1992,BoykovJolly2001,Krahenbuhl2011CRF}. Morphological constraints such as minimum size, compactness, or adjacency to vesicle-rich zones filtered implausible detections, especially in 2D TEM where axial context was unavailable. Despite these priors, ambiguities among mitochondria, dense-core vesicles, and true synapses remained a dominant source of false positives.

\noindent\textbf{Strengths, limitations, and lessons.}
Pre-DL systems were computationally lightweight, interpretable, and amenable to user control. They also established evaluation practices (precision and recall on detections, boundary distances) and interactive proofreading paradigms later adopted by learning-based methods. However, strong dataset-specific tuning, limited 3D context utilisation, and brittle generalisation across labs, tissues, and species curtailed their scalability. Community benchmarks in the early 2010s catalysed progress but also exposed the ceiling of hand-engineered features on EM connectomics data \parencite{ArgandaCarreras2015}. These limitations motivated a shift to data-driven encoders and decoders with 3D context, while preserving useful elements of the classical toolchain (e.g., CRF and watershed post-processing and interactive correction) as modules in modern pipelines.

\subsection{Deep learning paradigms}
\label{sec:synapse-deeplearning}

Modern synapse segmentation is dominated by encoder--decoder convolutional networks adapted to EM and LM idiosyncrasies, with growing use of multi-task heads, data-efficient training, domain adaptation, and hybrid attention mechanisms. We organise this landscape along five design axes.

\noindent\textbf{2D vs.\ 3D U-Net families (evidence for 3D and memory trade-offs).}
U-Net backbones remain the workhorse across modalities \parencite{Ronneberger2015UNet,Cicek2016UNet3D,Isensee2021nnUNet}. On EM, 3D variants leverage through-plane context to resolve slice ambiguities and preserve topology; multiple studies and reviews report consistent gains of 3D over 2D for synaptic and ultrastructural targets, particularly for small and crowded objects \parencite{Alzubaidi2025,Buhmann2021}. The practical constraint is memory: volumetric patches and wider feature maps increase VRAM quadratically and cubically with context size. State-of-practice mitigations include overlap-tiling at inference, patch-wise training with halo margins, cascaded coarse\,$\rightarrow$\,fine stages, and anisotropic kernels in early layers to respect through-plane resolution while controlling cost \parencite{Isensee2021nnUNet,Cicek2016UNet3D}. Where memory is prohibitive (very large FIB-SEM or serial TEM stacks), 2.5D designs can be competitive but generally underperform true 3D on synapse-scale geometry.

\noindent\textbf{Multi-task \& component-aware heads (cleft and vesicle or active zone joint learning).}
Biologically plausible synapses consist of coordinated ultrastructures (cleft densities, vesicle clusters, active zones). Component-aware decoders exploit this by predicting multiple elements jointly, either via multi-head supervision (separate logits per component) or shared encoders with relational priors. This auxiliary structure supervision helps disambiguate look-alikes (e.g., mitochondria vs.\ boutons) and reduces merge or split errors by encoding expected geometric co-occurrence \parencite{Buhmann2021,Alzubaidi2025}. Recent pipelines report that multitask signals (e.g., vesicle heatmaps plus cleft masks) stabilise training under class imbalance and improve partner assignment when combined with neurite-contact constraints \parencite{Muth2025SynapseNet,Buhmann2021}.

\noindent\textbf{Self- and semi-supervised learning \& transfer (pretraining, pseudo-labels, distribution-aware weights).}
Annotation scarcity in human EM and weak labels in LM motivate pretraining on large unlabeled corpora and semi-supervised fine-tuning. Self-supervised schemes (contrastive, masked-reconstruction, rotation and jigsaw) learn domain-appropriate filters that transfer to synapse masks with limited labels; semi-supervised pipelines augment with pseudo-labels, often filtered by confidence or reweighted to counter class imbalance and domain bias \parencite{Achard2025CellSeg3D,Xiao2023ActiveLearning}. Transfer from animal EM to human tissue is common but requires careful calibration; distribution-aware reweighting and active learning (querying most uncertain and error-prone regions) reduce annotation burden while targeting rare synapse morphologies \parencite{Xiao2023ActiveLearning,Alzubaidi2025}.

\noindent\textbf{Domain adaptation \& augmentation (stain and prep or species shift; style transfer and feature alignment).}
Inter-lab variability (fixatives, stains), modality differences (TEM vs.\ SBEM vs.\ FIB-SEM), and species and tissue shifts cause pronounced appearance changes that degrade generalisation. Unsupervised domain adaptation aligns source and target either in image space (style transfer, histogram, and stain normalisation, synthetic missing sections) or feature space (adversarial alignment, adaptive normalisation, domain-mixed training). Benchmarks targeted at synapse detection emphasise this gap and evaluate adaptation explicitly \parencite{Li2024WASPSYN}. Robust pipelines combine aggressive, physics-aware augmentations (elastic warps, section dropouts, stain jitter) with multi-domain training and test-time adaptation; neurite-graph constraints further suppress biologically implausible predictions under shift \parencite{Buhmann2021,Alzubaidi2025,Li2024WASPSYN}.

\noindent\textbf{Hybrid CNN--Transformer \& generalist models (Transformer hybrids; SAM and MedSAM and 3D adaptations).}
Hybrid CNN--Transformer encoders aim to couple strong local inductive biases with long-range context (self-attention), and have shown gains on several biomedical benchmarks when data scale and regularisation suffice \parencite{Chen2021TransUNet,Isensee2021nnUNet}. For synapses, early evidence suggests hybrids can stabilise context aggregation in thick volumes, though carefully tuned 3D CNN baselines remain competitive. In parallel, generalist promptable segmenters (e.g., Segment Anything, SAM) are being adapted to medical images. Out-of-the-box SAM underperforms on ultrastructure; domain-adapted variants (DB-SAM and MedSAM) and EM-specific adaptations show improved transfer, yet require fine-tuning, prompt engineering, or 3D adaptations to approach specialised models \parencite{Kirillov2023SAM,Qin2024DBSAM,Cai2025SAM4EM}. Current evidence points to promise for annotation efficiency and interactive correction, with open questions around volumetric context, small-object sensitivity, and computational efficiency in teravoxel regimes.

\subsection{Structural priors \& constraints}
\label{sec:synapse-structural-priors}

Learning alone can yield anatomically implausible synapse masks (isolated clefts, partner swaps, or topologically broken contacts). Synapse-level segmentation therefore benefits from \emph{structural priors} that encode biological feasibility. We organise these priors into neuron-graph constraints, morphology and size priors, and topology-aware objectives, and emphasise \emph{soft}, differentiable implementations to avoid suppressing legitimate but rare synaptic variants.

\noindent\textbf{Neuron-graph constraints (contact graph $\rightarrow$ candidates $\rightarrow$ true and false synapse classification).}
In EM connectomics, synapses are edges between neurite segments. A practical pipeline therefore (i) reconstructs neurites, (ii) enumerates membrane \emph{contacts} between putative axons and dendrites to form a \emph{contact graph}, and (iii) classifies each contact as synaptic or not \parencite{Buhmann2021,Alzubaidi2025}. This construction yields powerful \emph{a priori} constraints: a predicted synapse must connect two \emph{distinct} segments; partner identities must be consistent across adjacent slices; and one contact should not spawn implausibly many synapses. Operationally, region-adjacency graphs (RAGs) or skeleton graphs serve as substrates on which features from image space (cleft textures, vesicle density) and geometry (contact area, curvature, relative orientation) are aggregated before binary classification. Graph constraints can further regularise instance segmentation by (a) vetoing isolated \enquote{floating} synapse masks without valid partners, (b) resolving collisions by assigning each contact at most one synapse instance, and (c) improving \emph{synaptic partnership accuracy}---an edge-level metric directly aligned with connectome correctness \parencite{Buhmann2021}. In multi-domain settings, the graph scaffold also mitigates domain shift by anchoring decisions to neurite topology rather than raw appearance \parencite{Alzubaidi2025}.

\noindent\textbf{Morphology \& size priors (component co-geometry; minimum size and connectedness).}
Synapses exhibit characteristic ultrastructural \emph{co-geometry}: a thin cleft flanked by pre- and postsynaptic densities, with vesicle clusters near the presynaptic membrane. Component-aware decoders translate these priors into auxiliary predictions (cleft and vesicle or active-zone heads) whose spatial arrangement constrains the admissible mask configurations \parencite{Buhmann2021,Alzubaidi2025}. Post-hoc priors---minimum viable size, compactness, adjacency to vesicle-rich regions, and contiguity with neurite membranes---filter implausible detections and reduce false positives from mitochondria or dense-core vesicles. Because rigid thresholds risk discarding legitimate small synapses, \emph{soft} priors are preferred: e.g., size-sensitive penalties in the loss, distance transforms that encourage proximity between cleft and vesicle predictions, or confidence reweighting that downweights isolated, morphology-inconsistent masks while preserving recall on atypical cases \parencite{Alzubaidi2025}. When LM provides only punctate markers, analogous priors operate at the spot-detection level (minimum PSF-consistent size; co-localisation of pre- and post-markers), improving precision under optical variability.

\noindent\textbf{Topology-aware objectives (connectedness and holes or splits via soft topological constraints).}
Topological errors---broken clefts, spurious bridges, or hole artefacts---propagate to connectivity analyses even when region overlap is high. \emph{Topology-aware} losses penalise changes in qualitative structure, complementing pixel-wise criteria. Homology-inspired losses approximate Betti numbers or Euler characteristics to discourage unwanted components and holes \parencite{Clough2020TopoLoss}; projection-based relaxations compute connectivity on orthogonal projections to impose 3D connectedness with tractable gradients \parencite{Fu2024ProjectedPooling}. In practice, such terms are combined with Dice and IoU and boundary distances, and applied either to the synapse mask itself or to auxiliary centreline and affinity targets that better correlate with topological integrity. When coupled with neuron-graph constraints, topology-aware objectives reduce merge or split errors without hard-coding geometry, yielding masks that are simultaneously overlap-accurate and connectome-plausible \parencite{Buhmann2021,Fu2024ProjectedPooling}. Care is needed to balance these penalties: excessive topological rigidity can underfit genuine morphological variability, whereas too-weak terms fail to prevent catastrophic merges in ultra-dense neuropil.

\subsection{Evaluation \& failure modes}
\label{sec:synapse-eval-failure}

Evaluating synapse-level segmentation requires protocols that respect task formulation (point detection vs.\ mask segmentation), partner linkage, and the realities of dense, small objects under domain shift. We summarise matching rules, metric choices, and recurrent error modes, and outline reporting practices that expose strengths and weaknesses beyond a single headline score.

\noindent\textbf{Matching protocols and detection tolerances.}
For \emph{point or partner detection}, a prediction is matched to a ground-truth synapse if the Euclidean distance between centroids is below a tolerance $\tau$ (specified in voxels or nanometres), with one-to-one assignment via bipartite matching. When partner identities are predicted, matches additionally require correct pre- and postsynaptic partners; the resulting \emph{synaptic partnership accuracy} quantifies edge correctness on the connectivity graph \parencite{Buhmann2021}. For \emph{mask segmentation}, matches typically use an IoU threshold (e.g., $0.5$), yielding per-instance precision and recall and Average Precision (AP) across thresholds \parencite{Lin2014COCO}. At high densities, instance matching must be robust to small boundary jitter; practical protocols therefore (i) restrict many-to-one matches, (ii) break ties by maximal IoU (masks) or minimal distance (points), and (iii) report sensitivity analyses across $\tau$/IoU values to expose tuning brittleness.

\noindent\textbf{Metrics aligned with use cases.}
\autoref{sec:foundations-eval-fair} sets out the multi-metric protocol we adopt: overlap, boundary, and instance summaries reported together with transparent matching rules. For synapses, this toolkit must be extended with graph-level measures---synaptic partnership accuracy and edge-wise precision, recall, and F1---because voxel agreement alone does not certify correct wiring \parencite{Buhmann2021}. Boundary distances (HD95, ASSD) remain important when cleft morphology matters, whereas point-only counts can downplay them. Stratifying every metric by synapse size, intensity, and crowding prevents large or bright structures from dominating aggregate scores and exposes failure modes in dense neuropil.

\noindent\textbf{Canonical failure modes.}
\emph{False negatives (FN)} arise from tiny, low-contrast synapses and from axial inconsistency in 2D models; FNs depress recall and partnership completeness. \emph{False positives (FP)} frequently reflect mitochondria or dense-core vesicles misread as synapses, especially without component-aware cues; FPs inflate degree distributions in inferred graphs \parencite{Alzubaidi2025}. \emph{Partner misassignment} occurs when the cleft is detected but linked to the wrong neurites due to segmentation errors or ambiguous multi-contact interfaces; such errors may preserve region overlap yet corrupt connectome edges \parencite{Buhmann2021}. \emph{Merge or split} errors reflect instance disentanglement failures under high packing density. Ablations that toggle 3D context, component heads, and graph constraints help localise which design choices mitigate each failure class.

\noindent\textbf{Domain shift and robustness.}
Inter-laboratory variability (stains, fixation), modality differences (TEM, SBEM, and FIB-SEM), and species and tissue shifts can sharply degrade metrics when moving off-domain \parencite{Alzubaidi2025}. Dedicated evaluations (e.g., cross-domain synapse-detection challenges) document significant drops in AP and recall and increases in partner errors without adaptation \parencite{Li2024WASPSYN}. Robust reporting therefore includes per-domain breakdowns, leave-one-site-out protocols, and calibration plots to quantify overconfidence on shifted distributions. When adaptation is employed, fair comparison fixes source and target splits and discloses augmentation and normalisation recipes to avoid leakage.

\noindent\textbf{Diagnostic practice and reporting hygiene.}
Multi-metric tables benefit from (i) error maps highlighting FP confusions (e.g., mitochondria) and FN clusters (e.g., thin clefts in crowded neuropil), (ii) analyses stratified by size and crowding, and (iii) taxonomies of partnership errors (missed edges vs.\ swapped partners). Confidence intervals via nonparametric bootstrap over synapses or volumes improve statistical interpretability \parencite{Taha2015Metrics}. To stabilise claims, reuse the subject- and site-level splits prescribed in \autoref{sec:foundations-reproducibility}, include a strong self-configuring baseline (e.g., nnU-Net) for context, and release evaluation scripts and matching parameters \parencite{Isensee2021nnUNet}. When both point and mask outputs are available, report the full suite of metrics from \autoref{sec:foundations-eval-fair} (AP, PQ, AJI, DSC, HD95, ASSD) together with partnership accuracy so that downstream analyses can judge detection, segmentation, and graph correctness jointly.

\subsection{Synthesis \& gaps}
\label{sec:synapse-synthesis-gaps}

Synapse segmentation has matured into a coherent toolkit built on 3D encoder--decoder CNNs, component-aware supervision, and graph-informed constraints, yet its reliability remains tightly coupled to data conditions and evaluation practice. Below we synthesise when current approaches work, where they fail, and the data and methodological gaps that limit robust translation to human tissue.

\noindent\textbf{When current methods are effective.}
State-of-practice pipelines perform strongly when (i) training and test data share preparation and staining protocols, (ii) volumetric context is available or anisotropy is modest, and (iii) supervision captures synaptic \emph{co-geometry} via auxiliary heads for clefts, vesicles, and active zones \parencite{Alzubaidi2025,Buhmann2021}. Under such conditions, 3D U-Net families with cascaded tiling, anisotropic kernels, and halo margins deliver superior continuity to 2D baselines, reducing merge or split errors in dense neuropil \parencite{Isensee2021nnUNet}. Data-efficient training further stabilises performance: self- and semi-supervised schemes improve sample efficiency on limited labels, and active learning targets rare morphologies \parencite{Achard2025CellSeg3D}. Graph constraints that vet masks against neurite contacts increase \emph{synaptic partnership accuracy}, aligning voxel predictions with connectome correctness \parencite{Buhmann2021}.

\noindent\textbf{Where methods fail.}
Failure is most pronounced under severe distribution shift---across labs, fixatives, stains, EM modalities (TEM, SBEM, and FIB-SEM), species, or cortical layers---where appearance drift causes recall and AP to drop and partner misassignments to rise \parencite{Alzubaidi2025,Li2024WASPSYN}. Ultra-small, low-contrast synapses remain difficult, especially with strong anisotropy or missing sections that defeat slice-wise context. Component confusions (mitochondria or dense-core vesicles) inflate false positives when auxiliary cues are weak. Partner errors propagate from upstream neurite segmentation imperfections even when clefts are detected, revealing a disconnect between region overlap and graph correctness \parencite{Buhmann2021}. Practical constraints (VRAM, I/O) limit context size on teravoxel volumes, forcing patching regimes that may degrade topological integrity \parencite{Isensee2021nnUNet}. Finally, promptable generalist models (SAM and MedSAM variants) still underperform specialised 3D CNNs on ultrastructure unless carefully adapted, with open questions on volumetric attention and small-object sensitivity \parencite{Kirillov2023SAM,Qin2024DBSAM}.

\noindent\textbf{Data gaps.}
There is no large, publicly accessible human EM benchmark with dense synapse masks; existing human datasets are small and heterogeneous, limiting conclusions about cross-site robustness \parencite{Alzubaidi2025}. Partnership-level ground truth is sparse, hindering systematic evaluation of wiring correctness. While domain-adaptation challenges exist for small animals \parencite{Li2024WASPSYN}, analogous multi-site human benchmarks with hidden test sets and standardised matching protocols are lacking. Cross-scale, correlative LM--EM datasets remain limited, constraining research on multi-modal priors; at the macroscale, PET provides only regional synaptic density maps (e.g., SV2A) and cannot validate instance-level predictions \parencite{Johansen2024}.

\noindent\textbf{Methodological gaps.}
First, \emph{end-to-end graph-aware learning} is underdeveloped: most pipelines bolt graph constraints on post hoc, rather than train decoders to optimise partnership accuracy jointly with mask quality \parencite{Buhmann2021}. Second, \emph{topology-aware objectives} remain auxiliary; principled integration that balances Dice and IoU with homology projections at scale is an active area \parencite{Fu2024ProjectedPooling}. Third, robust \emph{domain generalisation} beyond pairwise adaptation is needed: multi-domain pretraining, adaptive normalisation, and test-time adaptation show promise but lack consensus recipes for EM \parencite{Alzubaidi2025,Li2024WASPSYN}. Fourth, \emph{generalist and promptable} segmenters require volumetric attention and EM-specific priors to match task-specific 3D CNNs \parencite{Kirillov2023SAM,Qin2024DBSAM}. Fifth, \emph{scalability} remains a bottleneck: sparse and blocked 3D computation and memory-efficient tiling are not yet standardised across toolchains \parencite{Isensee2021nnUNet}. Finally, \emph{cross-scale integration} (LM cues guiding EM search; EM priors regularising LM puncta) is largely ad hoc due to data scarcity \parencite{Achard2025CellSeg3D}.

\noindent\textbf{Evaluation and reporting gaps.}
A single region-overlap score obscures wiring errors; routine reporting should include AP, PQ, and AJI and partnership accuracy with size- and crowding-stratified analyses \parencite{Kumar2017AJI,Kirillov2019Panoptic,Buhmann2021}. External validation across unseen sites and modalities, fixed subject-site splits, and strong baselines (e.g., nnU-Net) are still inconsistently adopted \parencite{Isensee2021nnUNet}. Confidence intervals via bootstrap and public evaluation scripts are essential to separate algorithmic gains from protocol variance \parencite{Taha2015Metrics}.

\noindent\textbf{Outlook.}
Bridging these gaps likely requires (i) curated, multi-institution human EM benchmarks with partnership labels; (ii) graph-aware decoders optimised for connectome metrics; (iii) scalable 3D backbones with topology-aware learning; and (iv) principled, EM-aware adaptations of generalist models. Together with cross-modal datasets and transparent protocols, these advances would convert current in-domain successes into dependable synapse mapping across labs, species, and human brain regions.

\section{Cell-level Segmentation}

\subsection{Problem settings}
\label{sec:cell-problem-settings}

Cell-level segmentation targets biologically meaningful instances at cellular scale---typically neuronal somata, glial cells, and nuclei, with optional delineation of neurites (axon and dendrite shafts) and subcellular compartments. Compared with synapse detection, objects are larger and more morphologically diverse, but scenes remain crowded and heterogeneous across imaging modalities and laboratories. Here we outline task definitions and the modality- and site-specific factors that condition algorithm design and evaluation.

\noindent\textbf{Targets and annotation regimes.}
Common goals include (i) \emph{cell instance segmentation} (separating touching somata; reporting counts, sizes, and densities), (ii) \emph{nuclear instance segmentation} as a proxy for cell counts in densely labelled tissue, and (iii) \emph{neurite segmentation} (optionally centreline extraction) to capture morphology relevant to connectivity or degeneration. Annotation ranges from dense volumetric masks to weak labels (points and scribbles), the latter being frequent in very large 3D datasets. Instance-level outputs are generally preferred to enable biologically interpretable measures (cell densities, size distributions), while semantic labels may suffice for tissue compartmentalisation when object identity is secondary.

\noindent\textbf{Optical microscopy (LM): contrast, scale, and protocol variability.}
Confocal, two-photon, and light-sheet modalities provide sub-micron voxels with molecular specificity via fluorescent markers; super-resolution methods push below the diffraction limit locally. At whole-brain or cleared-tissue scales, volumes reach tera-voxels, necessitating 3D models, block-wise processing, and data-efficient learning under sparse ground truth \parencite{Achard2025CellSeg3D,Attarpour2025}. Practical challenges include depth-dependent attenuation, point-spread-function (PSF) anisotropy and elongation along $z$, inhomogeneous staining, bleaching, and sample-induced aberrations. Label specificity varies (pan-neuronal vs.\ nuclei markers), shifting ambiguity between soma and background or between closely apposed cells. Critically, inter-laboratory variability in optics (objective NA, immersion media), chemistry (labels, clearing), and acquisition parameters induces substantial domain shift; robust pipelines therefore rely on cross-site normalisation, stain and contrast augmentation, and, increasingly, self-supervised and semi-supervised pretraining to stabilise features across protocols \parencite{Achard2025CellSeg3D,Attarpour2025}.

\noindent\textbf{Electron microscopy (EM): membrane-resolved morphology and crowding.}
EM resolves cellular membranes and organelles at nanometre scales, enabling precise soma and neurite boundaries but at extreme data volumes and with pronounced anisotropy in serial-section stacks. Cell instances occupy large extents and abut other processes; merge or split errors propagate to morphology statistics. Tissue preparation (fixation, stains), modality (TEM, SBEM, FIB-SEM), and cortical layer and species differences shift texture and contrast, degrading cross-dataset generalisation \parencite{Alzubaidi2025}. Accurate segmentation typically requires 3D context, anisotropy-aware kernels, and topology-preserving objectives to avoid fragmentation of thin processes; when neurite morphology is also needed, centreline or skeleton consistency becomes a secondary target.

\noindent\textbf{Cross-laboratory and site differences and generalisation.}
Beyond modality, site effects (scanner, optics, protocols) are often the dominant driver of performance variance. Methods benchmarked on a single site can overestimate reliability; external validation on unseen sites and multi-centre training improve robustness but do not eliminate shift \parencite{Isensee2021nnUNet}. Reporting per-site metrics, uncertainty and calibration, and size-stratified results is therefore essential. In practice, pipelines combine normalisation (intensity, histogram, and stain), physics-aware augmentations (PSF and blur, depth-dependent noise), and domain-mixed training; for very large LM volumes, hierarchical tiling with overlap and halo margins mitigates block artefacts, while active learning focuses annotation on failure clusters \parencite{Achard2025CellSeg3D}.

\noindent\textbf{Implications for formulation and evaluation.}
Cell and nuclei instance segmentation benefits from 3D encoders with instance-aware decoders and small-object handling near the resolution limit (particularly for nuclei). For LM, PSF-aware post-processing and co-localisation checks (multi-channel markers) increase precision; for EM, topology-aware losses reduce fragmentation of thin processes. Given cross-site variability, fair comparison requires leakage-safe, subject- and site-level splits and multi-metric reporting (Dice and IoU with HD95 and ASSD for masks; AP, PQ, and AJI for instance quality), accompanied by external validation where available \parencite{Isensee2021nnUNet}. These settings frame the method choices detailed in the subsequent subsections.

\subsection{Classical $\rightarrow$ DL transition}
\label{sec:cell-classical-to-dl}

Cell-level segmentation has undergone a decisive shift from rule-based pipelines to learned encoders and decoders that operate in 2D and 3D, with classical components retained where they add stability (e.g., boundary refinement, instance separation). This subsection traces that transition and distils the practical consequences for optical and EM data.

\noindent\textbf{Rule-based pipelines and interactive shallow learning.}
Before deep learning, workflows combined contrast enhancement with hand-crafted segmentation: global and adaptive thresholding for nuclei or soma candidates \parencite{Otsu1979}, morphological filtering and watershed to split touching objects \parencite{BeucherMeyer1992}, active contours for smooth boundaries under weak gradients \parencite{ChanVese2001}, and graph-cut and CRF regularisers to align labels with edges \parencite{BoykovJolly2001,Krahenbuhl2011CRF}. In microscopy, a common recipe was distance-transform\,{+}\,watershed over a foreground mask to separate clustered nuclei. Semi-automatic toolkits (e.g., \textit{ilastik}) allowed experts to brush positive and negative examples and train Random Forests on texture and gradient features, providing rapid iteration on large 3D blocks with limited labels. These systems were lightweight and interpretable, but brittle across protocols and modalities, struggled with anisotropy and crowding, and required dataset-specific tuning.

\noindent\textbf{Entry of learned encoders: from 2D FCNs to U-Net.}
Early CNNs for medical images demonstrated that learned, multi-scale features outperform hand-crafted ones on heterogeneous data (e.g., MRI lesions) \parencite{Havaei2017BrainTumor}. U-Net introduced a symmetric encoder--decoder with skip connections that preserves fine detail while aggregating context and quickly became the default for cellular microscopy \parencite{Ronneberger2015UNet}. For volumetric LM and EM, 3D U-Net extended this design to dense 3D patches, markedly improving continuity and small-structure sensitivity over 2D models, at the cost of memory and I/O that necessitate patching with overlap and halo margins \parencite{Cicek2016UNet3D,Isensee2021nnUNet}.

\noindent\textbf{Stronger decoders and instance awareness.}
Architectural refinements---nested skip pathways and deep supervision in UNet\texttt{++}, and full-scale skip aggregation in UNet3\texttt{+}---further strengthened multi-scale fusion and boundary fidelity in crowded scenes \parencite{Zhou2018UNetpp,Huang2020UNet3Plus}. Proposal-free instance segmentation methods tailored to cells, notably StarDist (star-convex polygon and polyhedron regression) and generalist Cellpose (vector flows of spatial gradients), directly encode instance shape priors and excel at separating touching objects with limited supervision, complementing mask decoders on both LM and EM \parencite{Schmidt2018StarDist,Stringer2021Cellpose}. In practice, many pipelines fuse these with U-Net backbones (e.g., predicting star-distances or flow fields from U-Net features) to couple context with instance-aware outputs.

\noindent\textbf{Hybridisation with classical modules.}
Despite strong learned priors, post-processing from the classical era remains useful: CRF refinement aligns fuzzy boundaries to image gradients, and watershed seeded by CNN foreground and centroid maps robustly separates clumps; such hybrids consistently boost instance metrics (AJI and PQ) in dense tissues \parencite{Krahenbuhl2011CRF,BeucherMeyer1992}. Interactive correction also persists: probability maps from U-Net-family models provide reliable starting points for proofreading or active-learning loops that target systematic errors. Self-configuring frameworks (nnU-Net) standardise much of this pipeline (preprocessing, patching, tiling), providing competitive baselines across sites and modalities \parencite{Isensee2021nnUNet}.

\noindent\textbf{Practical takeaways.}
For LM with protocol variability and teravoxel scale, 3D U-Net backbones with instance-aware heads (StarDist and Cellpose-style) and classical separation (watershed) offer strong accuracy--throughput trade-offs; for EM, 3D encoders with anisotropy-aware kernels improve topology and reduce merge or split errors, with CRF and watershed used sparingly for boundary clean-up. Across modalities, the shift from rules to learned representations delivers robustness and scalability, while the best-performing systems retain classical modules where they address known failure modes (touching-instance separation, boundary drift) under limited supervision.

\subsection{Deep learning paradigms}
\label{sec:cell-deeplearning}

Contemporary cell- and nuclei-level instance segmentation leverages encoder--decoder architectures that fuse multi-scale context with instance-aware decoding, extended to 3D for volumetric microscopy and coupled with weak and interactive supervision and domain-robust training. We organise representative advances into five themes.

\noindent\textbf{U-Net++/UNet3\texttt{+}, attention and dilation, and multi\-scale pyramids.}
Beyond the canonical U-Net, nested and deeply supervised skip pathways in UNet\texttt{++} and full-scale aggregation in UNet3\texttt{+} strengthen multi-scale fusion and boundary fidelity in crowded cellular scenes \parencite{Zhou2018UNetpp,Huang2020UNet3Plus}. Attention gates (``Attention U-Net'') suppress irrelevant responses in cluttered fields and improve focus on faint cell contours \parencite{Oktay2018AttentionUNet}, while atrous and dilated convolutions enlarge receptive fields without downsampling, preserving localisation for small nuclei and thin somata \parencite{Chen2017Atrous,Yu2016Dilated}. Complementary pyramid designs such as FPN-style decoders propagate high-level semantics to fine resolutions and are frequently integrated with U-Net backbones for robust small and large cell coexistence \parencite{Lin2017FPN}. In practice, these elements (nested skips, attention, dilation, pyramids) are combined to balance context aggregation with precise boundaries under label scarcity.

\noindent\textbf{3D CNNs for volumetric microscopy (break and adhesion control).}
For 3D LM and EM volumes, 3D U-Net and V-Net backbones markedly reduce through-plane flicker and improve topology compared to 2D and 2.5D baselines \parencite{Cicek2016UNet3D,Milletari2016VNet,Isensee2021nnUNet}. Instance errors concentrate in two modes: (i) \emph{breaks} (over-segmentation) of thin processes and elongated nuclei; and (ii) \emph{adhesions} (under-segmentation) where touching somata and neighbouring processes fuse. Remedies include boundary-/centerline-aware auxiliaries (e.g., boundary loss, centreline and affinity prediction), seeded watershed over CNN foregrounds, and cascaded coarse\,$\rightarrow$\,fine inference with halo margins to reduce tiling artefacts \parencite{Kervadec2019BoundaryLoss,BeucherMeyer1992,Isensee2021nnUNet}. For EM neurites, long-range context via flood-filling networks (FFNs) or affinity-graph decoders further reduces merge or split frequency at cell boundaries while maintaining soma fidelity \parencite{Januszewski2018FFN}.

\noindent\textbf{Transformer hybrids \& foundation-model adaptation (SAM and MedSAM, point-guided, interactive).}
Transformer hybrids (e.g., TransUNet, UNETR) combine convolutional locality with global self-attention, yielding gains when volumes and labels suffice, while tuned 3D CNNs remain strong baselines in many microscopy settings \parencite{Chen2021TransUNet,Hatamizadeh2022UNETR,Isensee2021nnUNet}. Promptable generalist segmenters (SAM) are increasingly adapted to biomicroscopy for annotation efficiency and interactive correction; medical variants (DB-SAM, MedSAM) and domain adapters improve transfer but typically require fine-tuning and careful prompting for tiny, low-contrast cellular targets, especially in 3D \parencite{Kirillov2023SAM,Qin2024DBSAM,Ma2023MedSAM}. Point and scribble guidance integrates naturally with these models, supporting rapid proofreading and human-in-the-loop refinement in teravoxel regimes.

\noindent\textbf{Weak and point or scribble supervision \& active learning (label efficiency and human--AI collaboration).}
To curb annotation cost, weak supervision utilises points, scribbles, or coarse masks to supervise dense predictions via region-growing, consistency, or topology-aware regularisers; point- and scribble-supervised frameworks demonstrate competitive instance quality with a fraction of labels \parencite{Bearman2016PointSup,Tang2018ScribbleSup}. Interactive loops further increase yield: uncertainty- or diversity-driven active learning (``suggestive annotation'') prioritises blocks and slices for expert review, accelerating coverage of rare morphologies and failure clusters in large volumes \parencite{Yang2017Suggestive,Xiao2023ActiveLearning}. In practice, pipelines pair 3D U-Net backbones with weak labels (points and scribbles), CRF and watershed separation, and periodic human corrections to achieve scalable, high-fidelity cell maps.

\noindent\textbf{Generalisation across labs and devices (normalisation, domain-mixed training, test-time adaptation).}
Inter-site variability (optics, staining and clearing, scanners) often dominates error budgets. Robust training therefore combines per-site normalisation, strong physics-aware augmentation (PSF and blur, depth-dependent noise), and domain-mixed mini-batches to learn site-invariant features \parencite{Isensee2021nnUNet}. Feature-space alignment (adversarial domain adaptation) and adaptive normalisation (AdaBN) mitigate residual shifts without target labels \parencite{Ganin2016DANN,Li2016AdaBN}. At deployment, test-time adaptation (e.g., entropy minimisation, TTA) refines normalisation and affine statistics to the target distribution on the fly, improving calibration and recall on unseen microscopes and scanners \parencite{Wang2021Tent}. External validation and per-site stratified reporting remain essential to substantiate claims of generalisation under real laboratory heterogeneity.

\subsection{Evaluation \& typical errors}
\label{sec:cell-eval-errors}

Reliable assessment of cell and nuclei instance segmentation requires metrics and diagnostics that expose object-wise correctness, boundary fidelity, and robustness to crowding and small targets. We outline recommended measures and relate them to three canonical error modes: over-/under-segmentation, small-object misses, and boundary jitter.

\noindent\textbf{Multi-metric reporting.}
Pixel and region overlap scores (Dice, IoU) summarise mask agreement but can conceal instance confusion in crowded fields and are biased toward large objects. It is therefore appropriate to pair Dice and IoU with boundary distances (HD95, ASSD) to quantify contour fidelity, and with instance-aware measures---Average Precision (AP across IoU thresholds), Panoptic Quality (PQ), and the Aggregated Jaccard Index (AJI)---to capture detection--segmentation trade-offs and splitting and merging behaviour \parencite{Taha2015Metrics,Lin2014COCO,Kirillov2019Panoptic,Kumar2017AJI}. Stratification by size (e.g., small, medium, and large nuclei, soma diameter bins) and by local crowding (nearest-neighbour distance) prevents easy, large instances from dominating summary scores. Strong, self-configuring baselines (e.g., nnU-Net) under identical splits help contextualise effect sizes \parencite{Isensee2021nnUNet}.

\noindent\textbf{Over- and under-segmentation (instance splitting and merging).}
\emph{Over-segmentation} breaks one cell into fragments (e.g., elongated somata or nuclei fractured by low-contrast seams), inflating counts and depressing AJI and PQ despite reasonable Dice. \emph{Under-segmentation} fuses touching instances into one label, reducing counts and depressing AP at stricter IoU thresholds. Diagnostics should include (i) per-image fragmentation and adhesion rates (mean predicted instances per ground-truth object and vice versa), (ii) AJI and PQ alongside Dice and IoU, and (iii) error maps highlighting systematic splits and merges near thin bridges or high-density clusters. Remedies commonly improve these metrics: seeded watershed over CNN foregrounds, centreline and affinity auxiliaries, and topology-aware regularisers reduce both fragments and adhesions in 3D volumes \parencite{BeucherMeyer1992,Kervadec2019BoundaryLoss,Isensee2021nnUNet}.

\noindent\textbf{Small-object miss (low recall on tiny and low-contrast instances).}
Small nuclei or soma near the optical resolution limit are frequently missed, especially under anisotropic point-spread functions or depth attenuation. Because Dice and IoU are size-biased, such misses may scarcely perturb global overlap while severely impacting biological readouts (densities, size distributions). Accordingly, it is informative to report (i) AP with small-object bins (``AP$_\mathrm{S}$'') and recall at lenient IoU (e.g., 0.1--0.3) to probe detection sensitivity, (ii) size-binned recall and precision curves, and (iii) calibration plots to identify overconfident negatives on small targets \parencite{Lin2014COCO,Guo2017Calibration}. Architecturally, multi-scale pyramids, dilated context, and small-object reweighting tend to improve these stratified metrics (see Sec.~\ref{sec:cell-deeplearning}).

\noindent\textbf{Boundary jitter (contour oscillation and systematic bias).}
Boundary errors manifest as jagged contours (slice-to-slice oscillation in 3D stacks) or systematic inward and outward bias (over-smoothing vs.\ halo expansion). These have limited impact on Dice for large cells but are captured by HD95 and ASSD; reporting both distances differentiates isolated outliers (HD95) from pervasive small deviations (ASSD) \parencite{Taha2015Metrics}. Boundary-aware losses and post-hoc CRF refinement reduce jitter and bias, improving HD95 and ASSD at similar Dice \parencite{Kervadec2019BoundaryLoss,Krahenbuhl2011CRF}. For 3D volumes, cascaded inference with halo margins and overlap tiling mitigates block-edge artefacts that otherwise inflate HD95 \parencite{Isensee2021nnUNet}.

\noindent\textbf{Recommended protocol.}
A minimal, informative report should include: (i) Dice and IoU, HD95 and ASSD; (ii) AP@$\{0.50{:}0.95\}$, PQ, and AJI; (iii) size- and crowding-stratified breakdowns; (iv) calibration curves and confidence intervals via nonparametric bootstrap over objects or volumes; and (v) qualitative panels of typical failure modes (splits, merges, missed small cells, boundary jitter). External validation or leave-one-site-out analyses are essential where cross-lab and device generalisation is claimed \parencite{Isensee2021nnUNet}. Such multi-view evaluation exposes trade-offs that single metrics obscure and aligns assessment with downstream biological endpoints.

\subsection{Synthesis \& gaps}
\label{sec:cell-synthesis-gaps}

Cell- and nuclei-level instance segmentation has converged on a practical recipe: 3D encoder--decoders with robust multi-scale fusion, instance-aware decoding and classical separation (watershed and CRF) for crowded scenes, trained with data-efficient supervision and evaluated with instance-aware metrics under leakage-safe splits \parencite{Isensee2021nnUNet}. Yet reliability and deployability remain bounded by cross-lab and device shift, small-object sensitivity, and the computational burden of teravoxel volumes. Below we synthesise what works, where failures persist, and outline a transferable paradigm for \emph{robust} instance segmentation with \emph{lightweight} inference.

\noindent\textbf{What works reliably.}
When training and deployment conditions are aligned, 3D U-Net families (with anisotropy-aware kernels and cascaded tiling) reduce slice flicker and merge or split errors relative to 2D and 2.5D baselines; instance-aware heads (e.g., StarDist and flow fields) plus seeded watershed improve separation of touching somata; weak-/interactive supervision and active learning reduce annotation burden at scale; and external or leave-one-site-out validation exposes overly optimistic in-domain estimates \parencite{Isensee2021nnUNet,Achard2025CellSeg3D}. For very large LM volumes, block-wise processing with overlap and halo and mixed-precision inference sustains throughput without degrading topology.

\noindent\textbf{Where methods still fail.}
Performance falls under substantial protocol shifts (optics, stains and clearing, scanners) and EM modality changes, with elevated small-object miss rates and adhesion of closely apposed cells; boundary jitter inflates HD95 where tiling and normalisation are brittle \parencite{Isensee2021nnUNet}. Lightweight backbones ported from natural images (mobile and edge models) can underfit fine cellular boundaries unless adapted to 3D and augmented with boundary and centreline auxiliaries. Finally, memory and IO limits constrain 3D context and receptive field, trading small-object recall against throughput.

\noindent\textbf{A transferable paradigm for robust, lightweight instance segmentation.}
\vspace{0.25em}
\emph{(i) Architecture:)} start from a strong 3D encoder--decoder baseline and replace dense convolutions where possible with depthwise and inverted residual blocks to cut multiply--accumulate cost \parencite{Howard2017MobileNet,Sandler2018MobileNetV2}. For sparse morphologies (neurites, vasculature), adopt sparse and submanifold convolutions to avoid wasted computation \parencite{Graham2018Submanifold}. Maintain instance awareness via star-distance and flow heads or centerline and affinity auxiliaries, with a seeded watershed to stabilise separation in dense tissue. \emph{(ii) Training:)} combine domain-mixed mini-batches and physics-aware augmentation (PSF and blur, depth attenuation) with self-supervised and semi-supervised pretraining when labels are scarce; prioritise active learning to target rare failures. \emph{(iii) Normalisation \& adaptation:)} use adaptive normalisation (e.g., per-site BN statistics) and, at deployment, test-time adaptation of normalisation and entropy to the target distribution \parencite{Li2016AdaBN,Wang2021Tent}. \emph{(iv) Compression:)} distil from a high-capacity teacher to a compact student and apply structured pruning and post-training INT8 quantisation to meet memory and latency budgets while preserving calibrated confidence \parencite{Hinton2015Distillation,Han2016DeepCompression,Jacob2018Quantization}. \emph{(v) Inference system:)} tile with overlap and halo margins; stream data to minimise IO stalls; run mixed precision (FP16/INT8) on GPU and edge NPUs; and export reproducible containers with fixed pre- and post-processing to ensure cross-site repeatability. 

\noindent\textbf{Key gaps and research opportunities.}
First, \emph{small-object robustness} remains fragile under cross-site shift; principled small-object reweighting and shape-aware priors for mobile backbones are needed to prevent recall collapse at low contrast. Second, \emph{3D-efficient design} is immature: depthwise and inverted residuals and sparse operators are well-studied in 2D but lack canonical, empirically vetted recipes for 3D biomedical volumes. Third, \emph{calibrated lightweight models} are underexplored: pruning and quantisation can distort uncertainty, undermining triage; joint objectives for accuracy and calibration deserve attention. Fourth, \emph{foundation-model adaptation} remains largely 2D and prompt-heavy; robust, EM and LM-aware 3D adaptations that retain small-object sensitivity are an open frontier. Finally, \emph{benchmarking for efficiency} is inconsistent: few works report standardised accuracy--latency--memory trade-offs across sites and hardware, hindering fair comparison and reproducible deployment.

\noindent\textbf{Outlook.}
A pragmatic path to portable cell segmentation couples (a) instance-aware 3D decoders with sparse and efficient operators, (b) domain-mixed training plus test-time adaptation, and (c) teacher$\rightarrow$student distillation with quantisation and pruning---all evaluated under external and site-stratified protocols with multi-metric reporting and calibration. Such a paradigm turns lab-specific prototypes into deployable tools for whole-brain LM and EM at scale, without sacrificing biological validity or reproducibility.

\section{Region-level Brain Segmentation}

\subsection{Definitions \& pipelines}
\label{sec:region-definitions-pipelines}

Region-level brain segmentation aims to assign anatomical or functional labels at the scale of cortical areas and subcortical nuclei from magnetic resonance (MR) or multi\-modal neuroimaging. Two canonical processing paradigms are prevalent: \emph{voxel-based} pipelines that operate in the native volumetric grid, and \emph{surface-based} pipelines that reconstruct and analyse the cortex on topology-preserving meshes. The choice affects geometric fidelity, cross-subject alignment, and the ease of multi\-modal fusion.

\noindent\textbf{Voxel-based (volumetric) pipelines.}
A typical volumetric workflow comprises (i) preprocessing (bias-field correction, denoising, intensity normalisation), (ii) spatial normalisation to a template, and (iii) label inference via atlas priors, label fusion, or learned voxelwise classifiers. Classical systems registered one or multiple labelled atlases to the subject and transferred labels with Markov and conditional random fields or statistical label fusion \parencite{Iglesias2015MALF}. Modern variants replace or augment atlas priors with deep encoder--decoder models (e.g., nnU-Net) tailored to 3D MR volumes and multi\-contrast inputs (T1/T2/FLAIR), often with cascaded tiling and anisotropy-aware kernels \parencite{Isensee2021nnUNet}. Voxel pipelines remain the default for subcortical structures (e.g., thalamus, basal ganglia) and lesions, where volumetric topology and tissue intensities are informative and where mesh reconstructions are unnecessary. Their limitations for cortex include partial-volume effects at the thin cortical ribbon and imperfect across-subject alignment when folding patterns vary substantially.

\noindent\textbf{Surface-based (cortical) pipelines.}
Surface methods explicitly reconstruct white and pial surfaces from volumetric MR, correct topology, and generate an intermediate midthickness surface; meshes are then inflated and mapped to a sphere to provide a low-distortion coordinate system for alignment and parcellation \parencite{Dale1999,Fischl2012}. Operating on surfaces preserves cortical topology and thickness profiles, reduces partial-volume confounds, and enables inter-subject registration driven by sulcal and gyral geometry or multi\-modal areal features. The Human Connectome Project (HCP) popularised multi\-modal surface analysis and delivered a 360-area cortical parcellation using myelin maps, resting-state functional connectivity, visuotopy, and architectonics \parencite{Glasser2016}. Recent advances accelerate cortical reconstruction for clinical-resolution MR \parencite{Henschel2020FastSurfer} and propose fast, learning-based spherical registrations that better respect areal boundaries \parencite{Ren2024SUGAR}. Surface pipelines are thus preferred for cortex-specific analyses (parcellation, thickness, folding), whereas subcortex is typically segmented in the voxel domain and optionally projected to surfaces for interface analyses.

\noindent\textbf{Registration-driven parcellation: geometry- vs.\ feature-informed alignment.}
Across subjects, parcellation quality depends critically on registration. Geometry-driven approaches align spherical meshes by curvature and sulcal depth and are robust when areal features are unavailable \parencite{Robinson2014MSM}. Feature-informed registrations additionally match myelin and relaxometry, functional connectivity, or task maps on the surface (``MSMAll and HCP''-style), improving areal correspondence in association cortex where folding is less predictive \parencite{Glasser2016}. Purely anatomical pipelines that learn areal instantiation from T1-weighted features demonstrate that geometry plus intensity-derived markers can yield robust label transfer in routine acquisitions \parencite{Nishimaki2024OpenMAPT1}. At cohort scale, automated, reproducible pipelines integrate these steps---from preprocessing through surface reconstruction, registration, and parcellation---to standardise outputs across scanners and sites \parencite{Ren2025DeepPrep}. In practice, robust workflows (i) couple voxel subcortical segmentation with surface cortical parcellation, (ii) use multi\-modal priors when available, and (iii) report site-stratified performance to quantify sensitivity to acquisition differences.

\noindent\textbf{Implications for multimodal fusion and evaluation.}
The surface provides a common coordinate system that facilitates the fusion of structural, functional, and quantitative MR (and PET) on the cortex, while the voxel space remains natural for deep nuclei and white matter tracts. Consequently, \emph{hybrid} pipelines---voxel for subcortex; surface for cortex---are increasingly standard. Regardless of paradigm, fair comparison requires leakage-safe, subject- and site-level splits, strong self-configuring baselines, and multi\-metric reporting (Dice and IoU and boundary distances for volumetric labels; surface-based overlap or geodesic distances for cortical parcels) \parencite{Isensee2021nnUNet,Glasser2016}.

\subsection{Classical atlas-based segmentation}
\label{sec:region-classical-atlas}

Atlas-based segmentation assigns regional labels by transporting prior anatomical knowledge from one or more labelled exemplars (\emph{atlases}) to a new subject. Two ingredients recur: (i) \emph{deformable registration} to align subject and atlas geometry, and (ii) \emph{label inference} using transferred labels and probabilistic priors. Despite the rise of deep learning, atlas methods remain reference standards for subcortical nuclei and cortical parcellations, and they continue to inform modern pipelines as priors, initialisations, and quality-control baselines.

\noindent\textbf{Multi-atlas registration and label fusion.}
Single-atlas transfer is vulnerable to registration idiosyncrasies. Multi-atlas segmentation mitigates this by warping multiple atlases to the subject and \emph{fusing} the propagated labels. Early schemes used majority voting; STAPLE introduced an expectation--maximisation framework that estimates rater (or atlas) performance and yields a probabilistically weighted consensus \parencite{Warfield2004STAPLE}. Subsequent \emph{joint label fusion} models downweight atlases whose local appearance is dissimilar to the target, improving boundary fidelity in heterogeneous anatomy \parencite{Wang2013JLF}. Registration quality is critical: diffeomorphic mappings (e.g., SyN in ANTs) preserve topology and reduce folding artefacts relative to elastic or B-spline warps \parencite{Avants2009SyN}. A comprehensive survey details design choices (atlas selection, pairwise vs.\ groupwise registration, fusion rules) and their effects across applications \parencite{Iglesias2015MALF}.

\noindent\textbf{Probabilistic priors and intensity models.}
Atlas priors can be encoded as voxelwise probability maps that enter Bayesian tissue and region models. Classical volumetric pipelines---notably SPM's \emph{Unified Segmentation}---combine a Gaussian mixture model of intensities with spatial priors and bias-field correction in a single generative optimisation, producing tissue classes and deformation fields jointly \parencite{Ashburner2005Unified}. FAST in FSL applies a hidden Markov random field with EM optimisation for robust tissue segmentation under noise and intensity inhomogeneity \parencite{Zhang2001FAST}. For subcortical structures, FIRST in FSL fits Bayesian shape--intensity models learned from manually labelled exemplars, constraining solutions to plausible morphologies \parencite{Patenaude2011FIRST}. Probabilistic cytoarchitectonic atlases (e.g., J{\"u}lich--Brain) provide fine-grained priors for cortical and subcortical areas that can be propagated by registration or projected to surfaces for areal analyses \parencite{Amunts2020JulichBrain}. These priors improve robustness in low-contrast regions, while clarifying uncertainty at boundaries via posterior probabilities.

\noindent\textbf{Software paradigms and cortical surface labelling.}
Widely used software stacks operationalise these ideas. \emph{FreeSurfer} reconstructs white and pial surfaces, enforces topological correctness, and labels cortex using curvature and myelin-driven priors and atlas constraints, while segmenting subcortex volumetrically \parencite{Fischl2012}. \emph{SPM}/\emph{CAT} emphasise generative tissue modelling with atlas priors in the volume \parencite{Ashburner2005Unified}; \emph{FSL} provides FAST and FIRST for tissues and deep nuclei \parencite{Zhang2001FAST,Patenaude2011FIRST}; \emph{ANTs} supplies diffeomorphic registration (SyN) and Atropos for multi-class segmentation with spatial priors \parencite{Avants2009SyN}. On the cortical surface, spherical registration drives areal alignment by sulcal depth and curvature or multi\-modal features (e.g., myelin and functional maps), enabling atlas transfer and parcellation with reduced partial-volume bias \parencite{Glasser2016}. In hybrid workflows, subcortex is segmented volumetrically (atlas or DL) and cortex is parcellated on surfaces, then results are reconciled for whole-brain analyses.

\noindent\textbf{Strengths, limitations, and contemporary role.}
Atlas-based methods are \emph{data-efficient}, interpretable, and often robust in small cohorts or rare anatomies, with uncertainty estimates from posterior and probability maps. Their chief liabilities are (i) sensitivity to registration errors (especially near thin cortex and deep nuclei interfaces), (ii) population bias inherited from the atlases, (iii) limited adaptability to strong protocol and site shifts without re\-registration or atlas retuning, and (iv) computational cost for multi-atlas ensembles. Consequently, modern pipelines increasingly use atlas outputs as priors, weak supervision, or calibration references for learned segmenters, while retaining atlas paths as transparent baselines and fail-safes under domain shift \parencite{Iglesias2015MALF,Glasser2016}.

\subsection{Deep learning paradigms}
\label{sec:region-deeplearning}

Deep learning for region-level brain segmentation spans volumetric encoders, CNN--Transformer hybrids, multimodal fusion for clinical MR (and PET and MR), and surface-aware models that embed geometric and connectomic priors. We summarise key design axes and their practical limits.

\noindent\textbf{3D U-Net baselines vs.\ tuned variants (residual, dense, and attention).}
Self-configuring 3D U-Net baselines (e.g., nnU-Net) remain strong across structural MR cohorts by standardising preprocessing, patching and tiling, anisotropy handling, and post-processing \parencite{Isensee2021nnUNet}. Tuned variants add residual and dense blocks for deeper feature reuse and attention gates to suppress confounders in heterogeneous anatomy; these refinements typically yield modest but consistent Dice and HD95 gains on subcortical labels and lesion segmentation under fixed splits \parencite{Isensee2021nnUNet}. Importantly, carefully tuned 3D CNNs often match or surpass more exotic backbones when training data are limited and intensity contrast is informative.

\noindent\textbf{CNN--Transformer hybrids (TransUNet and Swin-Unet: benefits and limits for anatomical labels).}
Hybrids that couple convolutional locality with Transformer self-attention (e.g., TransUNet, UNETR, Swin-Unet) can improve long-range context aggregation and inter-organ disambiguation in volumetric MR \parencite{Chen2021TransUNet,Hatamizadeh2022UNETR,Cao2021SwinUnet}. Reported gains are dataset-dependent: when anatomy is predominantly governed by local appearance and atlas priors, well-regularised 3D CNN baselines remain competitive; hybrids bring clearer benefits for large field-of-view anatomy, severe intensity heterogeneity, or multi-site cohorts where global context stabilises predictions. Their costs include increased memory and compute and a tendency to overfit on small cohorts without strong augmentation and weight decay; thus, hybrids should be benchmarked against nnU-Net under identical splits to substantiate added complexity.

\noindent\textbf{Multimodal fusion (T1/T2/FLAIR, PET and MR; missing-modality handling and generative completion).}
Jointly leveraging T1/T2/FLAIR is standard for tissue and lesion segmentation (e.g., BraTS protocols) and boosts small-structure delineation versus single-modality inputs \parencite{Menze2015BRATS}. Robust fusion must cope with missing sequences: HeMIS learns modality-wise embeddings and aggregates available inputs at test time, avoiding brittle imputation \parencite{Havaei2016HeMIS}. Alternative strategies include modality dropout during training, cross-modal distillation, and generative completion via image-to-image synthesis to hallucinate absent contrasts; adversarial and cycle-consistent models have been used to synthesise MR sequences or to bridge PET and MR contrast gaps for downstream segmentation \parencite{Chartsias2017Synth,Huo2018SynSegNet}. Generative completion can recover performance under controlled shifts but risks propagating synthesis bias; for regulatory-grade reporting, HeMIS-style hetero-modal inference with explicit uncertainty remains attractive.

\noindent\textbf{Surface-aware learning \& tract and functional priors (graphs, manifolds, and spatio-temporal models).}
Cortex-specific learning profits from models that operate on surfaces or spherical parameterisations, preserving topology and reducing partial volume. Spherical U-Net and related graph and spectral CNNs perform convolution on meshes, enabling parcellation directly in a surface coordinate system and improving areal boundary fidelity relative to voxel-space decoders \parencite{Zhao2019SphericalUNet}. Learning-based spherical registration further enhances areal alignment by attending to feature congruence beyond geometry \parencite{Ren2024SUGAR}. For white matter, tract-informed segmentation (e.g., TractSeg on FOD peaks) embeds streamline and tract priors, yielding robust bundle delineation without full tractography \parencite{Wasserthal2018TractSeg}. Functional priors (resting-state networks, task contrasts) can guide cortical parcel boundaries; hybrid pipelines align subjects with geometry plus myelin and functional features (HCP-style), or learn parcellations from structural T1 augmented by feature-aware registration when functional data are unavailable \parencite{Glasser2016,Nishimaki2024OpenMAPT1}. Extending these ideas, spatio-temporal encoders exploit fMRI dynamics to refine parcels, though evaluation remains sensitive to preprocessing and inter-session variability.

\noindent\textbf{Takeaways.}
On contemporary cohorts, (i) high-quality 3D CNN baselines set a strong bar; (ii) hybrids add value when long-range dependencies and multi-site heterogeneity dominate; (iii) hetero-modal fusion that tolerates missing sequences is crucial for clinical deployment; and (iv) surface-aware and tract and functional priors improve cortical and subcortical fidelity when geometry alone is insufficient. Across designs, claims should be anchored to leakage-safe splits, external validation, and multi-metric reporting to separate architectural gains from protocol variance.

\subsection{Priors \& constraints}
\label{sec:region-priors-constraints}

Deep anatomical structure and population regularities provide powerful signals to stabilise region-level segmentation, especially for small, low-contrast nuclei and variable association cortex. We summarise three complementary classes of priors---atlas and probabilistic priors, shape and symmetry constraints, and topology-aware objectives---and discuss their practical integration with modern learning pipelines.

\noindent\textbf{Atlas and probabilistic priors.}
Spatial priors derived from labelled cohorts remain effective regularisers. In voxel pipelines, multi-atlas probability maps or tissue priors enter generative or discriminative models to bias solutions toward anatomically plausible labels, improving robustness under noise and intensity drift \parencite{Iglesias2015MALF,Ashburner2005Unified}. For fine-grained cytoarchitectonic targets, probabilistic atlases such as J{\"u}lich–Brain provide voxelwise posteriors and uncertainty, which can be transported by diffeomorphic registration (e.g., SyN) and used as auxiliary channels or loss weights during training \parencite{Amunts2020JulichBrain,Avants2009SyN}. On the cortex, surface-based priors (inflated and spherical meshes with curvature or myelin features) guide parcellation and facilitate cross-subject alignment with reduced partial-volume bias \parencite{Fischl2012,Glasser2016}.

\noindent\textbf{Shape constraints and morphology-aware regularisation.}
Small subcortical nuclei benefit from shape priors that restrict solutions to plausible geometries learned from exemplars. Classical Bayesian shape–appearance models (e.g., FIRST) encode compact statistical modes of variation and penalise implausible deformations, yielding improved boundary consistency in low-contrast regions \parencite{Patenaude2011FIRST}. In deep networks, analogous effects are obtained by: (i) distance-transform or signed-distance supervision that encourages smooth, well-formed boundaries; (ii) auxiliary centreline or boundary heads to separate adjacent structures; and (iii) losses that penalise deviations from expected compactness or elongation. When priors are uncertain (e.g., pathology or atypical development), \emph{soft} shape constraints (as loss terms or posteriors used for reweighting) are preferable to hard projections to avoid erasing genuine anatomical variability \parencite{Iglesias2015MALF}.

\noindent\textbf{Bilateral symmetry and population constraints.}
For paired structures (e.g., thalamus, caudate, hippocampus), bilateral regularities can stabilise segmentation. Symmetry constraints include: (i) training with symmetric templates or mirrored augmentations; (ii) left–right consistency losses that penalise large inter-hemispheric volume or boundary discrepancies after atlas-informed flips; and (iii) shared feature encoders with hemisphere-specific decoders to balance invariance and flexibility. On the cortex, population-constrained surface registration (e.g., MSM and HCP-style with geometry and areal features) improves areal correspondence across hemispheres and subjects, enabling symmetry-aware parcellation without enforcing identical labels \parencite{Robinson2014MSM,Glasser2016}. Reporting left–right agreement (e.g., Dice and volume ratios) alongside overall accuracy is recommended to expose asymmetry-induced failure modes.

\noindent\textbf{Topology preservation for small nuclei and thin ribbons.}
Overlap-centric losses can yield topologically broken labels (holes, islands, bridges), which disproportionately affect small nuclei and thin structures (e.g., amygdalar subnuclei, cortical ribbon). Topology-aware objectives complement Dice and IoU by discouraging spurious components and preserving connectivity. Homology-inspired penalties approximate Betti numbers or Euler characteristics to regularise component count and holes, while projection-based relaxations impose connectedness with tractable gradients in 3D \parencite{Clough2020TopoLoss,Fu2024ProjectedPooling}. In practice, topology terms are combined with boundary-aware losses and minimum-size filters, and applied within cascaded 3D pipelines (with overlap and halo margins) to mitigate tiling artefacts that otherwise inflate breakage in tiny targets \parencite{Isensee2021nnUNet}.

\noindent\textbf{Practical integration.}
Effective use of priors follows three principles. First, \emph{softness}: incorporate priors as probabilistic inputs or differentiable penalties rather than hard constraints, to preserve atypical anatomy. Second, \emph{co-registration quality}: diffeomorphic, topology-preserving registration is essential when transporting atlas priors to avoid folding artefacts \parencite{Avants2009SyN}. Third, \emph{evaluation alignment}: when priors aim to preserve connectivity and shape, include boundary and topology metrics (HD95, ASSD, topology errors) in addition to region overlap, and stratify by structure size to ensure improvements are not dominated by large, easy regions \parencite{Glasser2016,Isensee2021nnUNet}. Under these practices, atlas, shape, symmetry, and topology priors significantly enhance robustness for cortex and subcortex, particularly in multi-site clinical settings.

\subsection{Robustness, calibration \& domain shift}
\label{sec:region-robustness-calibration}

Region-level segmentation models face substantial performance volatility across imaging sites, scanners, pulse sequences, and acquisition protocols. Robust deployment therefore hinges on (i) explicit quantification of cross-site shift, (ii) probability calibration and uncertainty estimation, (iii) harmonisation and adaptation strategies that respect anatomy, and (iv) reproducible evaluation with test--retest evidence.

\noindent\textbf{Sources and quantification of shift (site and scanner or protocol).}
Between-site differences (field strength, vendor, head coil), sequence choices (e.g., MPRAGE vs.\ MP2RAGE), and preprocessing variations alter tissue contrast and noise, degrading accuracy when models are evaluated off-domain. Quantification should include leave-one-site-out validation, fixed subject- and site-level splits, and stratified reports by site and scanner. Intensity harmonisation methods such as ComBat reduce scanner effects while preserving biological variance and have been applied to cortical thickness, subcortical volumes, and diffusion measures \parencite{Fortin2018ComBat}. Self-configuring baselines (e.g., nnU-Net) with domain-mixed training and strong augmentation provide stable references under protocol variability \parencite{Isensee2021nnUNet}.

\noindent\textbf{Calibration and uncertainty (confidence you can use).}
Miscalibrated probabilities obscure risk under domain shift. Beyond accuracy and Dice, report calibration metrics---Expected Calibration Error (ECE), reliability diagrams, and Brier score---and compare post-hoc calibration (temperature scaling) against raw softmax outputs \parencite{Guo2017Calibration}. For per-voxel and instance uncertainty, approximate Bayesian methods (Monte Carlo dropout) and deep ensembles provide epistemic and aleatoric signals that highlight low-confidence regions near boundaries or in out-of-distribution scans \parencite{Gal2016Dropout,Lakshminarayanan2017Ensembles}. Calibrated uncertainty supports triage (e.g., targeted proofreading) and qualifies site-level performance claims, particularly when deploying across heterogeneous clinical cohorts.

\noindent\textbf{Robustness strategies: harmonisation, domain generalisation, and adaptation.}
Pre-training on heterogeneous multi-site cohorts with domain-mixed mini-batches and physics-aware augmentation (bias field, resolution, noise) improves cross-site generalisation \parencite{Isensee2021nnUNet}. When sequence availability varies, hetero-modal inference (HeMIS) tolerates missing inputs without brittle imputation \parencite{Havaei2016HeMIS}. Feature-space alignment via adversarial training (DANN) and adaptive normalisation (AdaBN) further mitigates distribution mismatch without target labels \parencite{Ganin2016DANN,Li2016AdaBN}. At deployment, test-time adaptation refines batch-statistics or minimises prediction entropy on the target stream to recover accuracy and calibration under shift \parencite{Wang2021Tent}. Complementary intensity harmonisation (e.g., ComBat) can be applied to quantitative maps or hand-crafted features fed to learned models, provided that harmonisation is learned on training sites only to avoid leakage \parencite{Fortin2018ComBat}. For longitudinal studies, unbiased within-subject templates reduce scan--rescan variance and increase measurement stability for cortical and subcortical labels \parencite{Reuter2012Longitudinal}.

\noindent\textbf{Reproducibility and test--retest reporting.}
Robustness claims should be grounded in (i) external validation on previously unseen sites and scanners; (ii) test--retest analyses reporting Dice and IoU, surface distances, and volumetric ICCs across repeat sessions; and (iii) confidence intervals via nonparametric bootstrap at the subject or region level. Open neuroimaging initiatives established best practices for reliability and reproducibility analyses at cohort scale; analogous protocols for anatomical segmentation should include site-stratified metrics and Bland--Altman plots to expose systematic bias \parencite{Zuo2014NKIRS}. Reproducible pipelines (containerised preprocessing, fixed tiling and overlap, code-committed evaluation scripts) and strong baselines (nnU-Net) are essential to separate architectural advances from protocol variance \parencite{Isensee2021nnUNet}.

\noindent\textbf{Practical guidance.}
A pragmatic recipe for robust deployment is: (a) train with domain-mixed data and strong, anatomy-aware augmentation; (b) harmonise intensities and features with training-only estimates; (c) use hetero-modal designs for missing sequences; (d) calibrate probabilities and expose voxel-/region-level uncertainty; (e) enable light-weight test-time adaptation; and (f) validate externally with test--retest cohorts and site-stratified reports. Following this protocol improves reliability across scanners and protocols without sacrificing anatomical plausibility or transparency.

\subsection{Evaluation \& errors}
\label{sec:region-eval-errors}

Robust assessment of region-level segmentation must reflect voxel-/surface-level agreement, boundary fidelity, and volumetric accuracy across cortex and subcortical nuclei. Because thin cortical ribbons and small deep nuclei challenge overlap-based scores, multi-metric reporting, size-aware stratification, and reliability analyses are essential.

\noindent\textbf{5.6.1 Multi-metric reporting (overlap, boundary, volume).}
Region overlap metrics (Dice, Jaccard (IoU)) summarise label agreement but can be dominated by large structures and insensitive to boundary displacements in thin cortex. It is prudent to pair Dice and IoU with boundary distances such as the $95^\text{th}$ percentile Hausdorff distance (HD95) and the average symmetric surface distance (ASSD) to capture worst-case and typical contour errors, respectively \parencite{Taha2015Metrics}. For cortical parcellations, surface-based measures (geodesic distances between parcel boundaries; surface overlap on inflated and spherical meshes) better reflect areal misalignment than voxel-space distances, reducing partial-volume confounds \parencite{Fischl2012,Glasser2016}. Volumetric agreement should be quantified with absolute and relative volume differences, complemented by intraclass correlation coefficients (ICCs) across sessions or raters to gauge reliability beyond mean bias \parencite{Reuter2012Longitudinal}. Strong, self-configuring baselines (e.g., nnU-Net) under identical, leakage-safe splits provide context for effect sizes \parencite{Isensee2021nnUNet}.

\noindent\textbf{5.6.2 Thin cortex pitfalls (partial volume, misregistration, boundary drift).}
The 2--4\,mm cortical ribbon is highly susceptible to partial-volume effects and bias-field inhomogeneity, leading to boundary drift that inflates HD95 with only modest Dice changes. Misregistrations during volumetric alignment further misplace parcel borders, especially in association cortex where folding is variable. Surface-based reconstruction and spherical alignment mitigate these issues by enforcing topological correctness and operating in a geometry-respecting coordinate system, improving boundary fidelity and cross-subject correspondence \parencite{Fischl2012,Glasser2016}. Evaluation should therefore (i) report surface-based boundary distances in addition to voxel metrics, (ii) stratify errors by cortical thickness and sulcal depth, and (iii) assess sensitivity to smoothing and mesh resolution.

\noindent\textbf{5.6.3 Small subcortical nuclei bottlenecks (class imbalance, topology).}
Small, low-contrast nuclei (e.g., amygdalar subnuclei, thalamic subfields) are underrepresented and easily fractured or bridged by overlap-optimised decoders. Dice and IoU can be unstable for such labels; size-normalised metrics and structure-wise ICCs are recommended. Topology-aware objectives and losses can reduce holes and spurious islands, improving connectiveness without over-smoothing boundaries \parencite{Clough2020TopoLoss,Fu2024ProjectedPooling}. Probabilistic cytoarchitectonic priors (e.g., J{\"u}lich--Brain) provide uncertainty estimates near indistinct borders and can be used as auxiliary channels or weights during training and evaluation, clarifying whether errors stem from model limitations or intrinsic ambiguity \parencite{Amunts2020JulichBrain}. Reports should include minimum-size filtering policies and error maps highlighting typical confusions at nucleus interfaces.

\noindent\textbf{5.6.4 Error taxonomy and stratified analyses.}
Across cortex and subcortex, common errors include over-segmentation (parcel and nucleus fragmentation), under-segmentation (fusion across narrow isthmuses), and boundary bias (systematic inward and outward shifts). Diagnostic tables should present (i) Dice and IoU with HD95 and ASSD per region, (ii) absolute and relative volume bias and ICCs, (iii) size-binned performance (small, medium, and large labels), and (iv) site- and scanner-stratified scores to expose domain-shift sensitivity \parencite{Isensee2021nnUNet}. For cortical parcels, boundary-based analyses on the surface (e.g., mean geodesic deviation) should accompany voxel metrics; for small nuclei, topology-error counts (extra components, holes) complement overlap measures \parencite{Clough2020TopoLoss,Fu2024ProjectedPooling}. Where longitudinal scans are available, scan--rescan reproducibility (Dice and IoU, boundary distances, volumes) should be reported alongside Bland--Altman plots to reveal systematic drift \parencite{Reuter2012Longitudinal}.

\noindent\textbf{5.6.5 Recommended protocol.}
A minimal yet informative protocol includes: (a) Dice and IoU with HD95 and ASSD per structure; (b) surface-based boundary metrics for cortex; (c) absolute and relative volume differences with ICCs; (d) size- and site-stratified reporting; (e) topology-error summaries for small nuclei; and (f) external or test--retest validation with confidence intervals via nonparametric bootstrap. Adhering to these practices yields evaluations that are sensitive to thin-ribbon and small-nucleus failure modes and that better predict reliability under real-world variability \parencite{Isensee2021nnUNet,Glasser2016}.

\subsection{Synthesis \& gaps}
\label{sec:region-synthesis-gaps}

Region-level segmentation has coalesced around a pragmatic division of labour: voxel-space pipelines for subcortical nuclei and lesions, and surface-based pipelines for cortical parcellation, with multimodal MR fusion and atlas and shape priors improving stability. Strong 3D U-Net baselines (e.g., nnU-Net) serve as reliable volumetric backbones, while surface reconstruction and spherical registration standardise cortical geometry and enable feature-informed alignment \parencite{Isensee2021nnUNet,Fischl2012,Glasser2016}. Nevertheless, three stressors repeatedly expose limits: very small or low-contrast structures, cross-site protocol variability, and the need to maintain consistency between surface and volume representations.

\noindent\textbf{What works and when.}
Under matched acquisition protocols and clear tissue contrast, tuned 3D CNNs with atlas or probabilistic priors deliver accurate subcortical labels; surface pipelines with geometry and areal features (myelin, functional connectivity) delineate cortical areas with superior boundary fidelity to voxel decoders \parencite{Iglesias2015MALF,Glasser2016}. Multimodal fusion of T1/T2/FLAIR improves lesion and tissue delineation, while hetero-modal inference tolerates missing sequences in clinical cohorts \parencite{Menze2015BRATS,Havaei2016HeMIS}. Population-constrained registrations (e.g., MSM and HCP-style; learning-based spherical alignment) further enhance areal correspondence beyond folding geometry alone \parencite{Glasser2016,Ren2024SUGAR}. With leakage-safe splits and site-stratified validation, these components form robust pipelines for many cohorts \parencite{Isensee2021nnUNet}.

\noindent\textbf{Persistent bottlenecks.}
\emph{Small structures.} Dice and IoU are unstable for tiny, low-contrast nuclei; topology breaks (holes, islands, bridges) persist even when overlap appears high. Topology-aware objectives reduce but do not eliminate such errors, particularly under patch-based inference and anisotropic resolution \parencite{Clough2020TopoLoss,Fu2024ProjectedPooling}. \emph{Domain shift.} Multi-site variation in scanners and sequences degrades generalisation; domain-mixed training, adaptive normalisation, harmonisation (e.g., ComBat), and test-time adaptation help but require careful design to avoid leakage and miscalibration \parencite{Isensee2021nnUNet,Fortin2018ComBat,Li2016AdaBN,Wang2021Tent}. \emph{Surface--volume inconsistency.} Disagreements between voxel labels and surface parcellations (e.g., grey–white boundary placement, thin-ribbon biases) complicate cross-modal analyses, especially when surfaces are reconstructed from labels predicted by a purely volumetric model \parencite{Fischl2012,Glasser2016}.

\noindent\textbf{Toward consistent hybrid pipelines.}
Two integration principles are emerging. First, \emph{bidirectional consistency}: enforce agreement between voxel and surface representations via differentiable projections (volume-to-surface sampling and surface-to-volume rasterisation) and add losses that penalise discordant boundaries or label dropout across spaces. Second, \emph{prior-guided regularisation}: use probabilistic atlases and shape and symmetry priors as soft constraints (auxiliary channels or loss weights) rather than hard labels, preserving atypical anatomy while stabilising small nuclei and thin cortical ribbons \parencite{Amunts2020JulichBrain,Patenaude2011FIRST,Glasser2016}. Tract- and function-informed constraints can further regularise boundaries where intensity cues are weak, especially for cortex adjacent to major white-matter bundles \parencite{Wasserthal2018TractSeg}.

\noindent\textbf{Generalisation and calibration under shift.}
A practical recipe combines domain-mixed training, physics-aware augmentation (bias field, resolution, noise), hetero-modal inference for missing sequences, site-aware normalisation (AdaBN), and light-weight test-time adaptation of normalisation and entropy \parencite{Havaei2016HeMIS,Li2016AdaBN,Wang2021Tent}. To support trustworthy deployment, probability calibration (temperature scaling, ensembles) and uncertainty estimation should accompany accuracy metrics, with site- and scanner-stratified reports and test–retest analyses to quantify reproducibility \parencite{Isensee2021nnUNet,Reuter2012Longitudinal}. Intensity harmonisation (e.g., ComBat) aids group analyses of derived morphometrics, but should be estimated using training sites only to avoid information leakage \parencite{Fortin2018ComBat}.

\noindent\textbf{Open gaps.}
\emph{Small-structure fidelity} remains fragile: there is no consensus recipe that jointly optimises overlap, boundary, and topology for nuclei at or below voxel scale. \emph{Surface-aware learning in end-to-end frameworks} is nascent; many systems still treat surfaces as post-processing rather than primary learning domains. \emph{Multi-site benchmarks with fixed, leakage-safe splits} that couple voxel and surface ground truth are scarce, hindering fair comparison of fusion and registration strategies. Finally, \emph{efficiency} is under-reported: accuracy–latency–memory trade-offs across scanners and clinical hardware are seldom standardised, obscuring deployability.

\noindent\textbf{Outlook.}
Progress will likely come from (i) hybrid decoders trained with coupled surface and volume losses; (ii) topology-aware objectives paired with size-stratified reweighting for small nuclei; (iii) principled hetero-modal fusion with explicit uncertainty for missing sequences; and (iv) harmonised, multi-site evaluation protocols that include surface boundary metrics, topology counts, volumetric bias, and test–retest reliability \parencite{Isensee2021nnUNet,Glasser2016,Clough2020TopoLoss,Fu2024ProjectedPooling}. Together, these directions promise region-level segmentation that is faithful on small structures, resilient across domains, and coherent between surface and voxel representations.